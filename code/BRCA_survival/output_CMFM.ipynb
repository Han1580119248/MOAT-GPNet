{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b87dbca5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:34.107917Z",
     "iopub.status.busy": "2025-05-09T13:27:34.107404Z",
     "iopub.status.idle": "2025-05-09T13:27:36.938352Z",
     "shell.execute_reply": "2025-05-09T13:27:36.937664Z"
    },
    "papermill": {
     "duration": 2.83755,
     "end_time": "2025-05-09T13:27:36.939563",
     "exception": false,
     "start_time": "2025-05-09T13:27:34.102013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "import torch.nn.functional as F\n",
    "import nbimporter\n",
    "from network import *\n",
    "import os\n",
    "from utils import *\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ceb4f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:36.963873Z",
     "iopub.status.busy": "2025-05-09T13:27:36.963470Z",
     "iopub.status.idle": "2025-05-09T13:27:36.970270Z",
     "shell.execute_reply": "2025-05-09T13:27:36.969792Z"
    },
    "papermill": {
     "duration": 0.027079,
     "end_time": "2025-05-09T13:27:36.970931",
     "exception": false,
     "start_time": "2025-05-09T13:27:36.943852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed=42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "446fb3db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:36.979129Z",
     "iopub.status.busy": "2025-05-09T13:27:36.978719Z",
     "iopub.status.idle": "2025-05-09T13:27:36.981264Z",
     "shell.execute_reply": "2025-05-09T13:27:36.980845Z"
    },
    "papermill": {
     "duration": 0.007257,
     "end_time": "2025-05-09T13:27:36.981884",
     "exception": false,
     "start_time": "2025-05-09T13:27:36.974627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_class=2\n",
    "classifier_out_dim=2\n",
    "num_epoch=2500\n",
    "test_inverval = 50\n",
    "num_view = 3\n",
    "dim_hvcdn= 64\n",
    "batch_size = 153"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61bf9054",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:36.989996Z",
     "iopub.status.busy": "2025-05-09T13:27:36.989667Z",
     "iopub.status.idle": "2025-05-09T13:27:37.014555Z",
     "shell.execute_reply": "2025-05-09T13:27:37.014073Z"
    },
    "papermill": {
     "duration": 0.029642,
     "end_time": "2025-05-09T13:27:37.015207",
     "exception": false,
     "start_time": "2025-05-09T13:27:36.985565",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.4388849177984275</th>\n",
       "      <th>0.0971396987702086</th>\n",
       "      <th>0.1464783281733745</th>\n",
       "      <th>0.3202959830866808</th>\n",
       "      <th>0.7835778781038374</th>\n",
       "      <th>0.1506017191977076</th>\n",
       "      <th>0.1820076415422022</th>\n",
       "      <th>0.1053309296935359</th>\n",
       "      <th>0.1597501115573404</th>\n",
       "      <th>0.7057069269350684</th>\n",
       "      <th>...</th>\n",
       "      <th>0.1938997821350765</th>\n",
       "      <th>0.7852328890220159</th>\n",
       "      <th>0.3521194605009633</th>\n",
       "      <th>0.2169369369369371</th>\n",
       "      <th>0.8426470588235293</th>\n",
       "      <th>0.228607594936709</th>\n",
       "      <th>0.2920901458241273</th>\n",
       "      <th>0.7171229200214708.1</th>\n",
       "      <th>0.82016210739615</th>\n",
       "      <th>0.1997296383913485</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.679056</td>\n",
       "      <td>0.018654</td>\n",
       "      <td>0.016060</td>\n",
       "      <td>0.593929</td>\n",
       "      <td>0.876552</td>\n",
       "      <td>0.129513</td>\n",
       "      <td>0.020493</td>\n",
       "      <td>0.895957</td>\n",
       "      <td>0.035029</td>\n",
       "      <td>0.925173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.926764</td>\n",
       "      <td>0.204239</td>\n",
       "      <td>0.061622</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.131329</td>\n",
       "      <td>0.093239</td>\n",
       "      <td>0.856414</td>\n",
       "      <td>0.959642</td>\n",
       "      <td>0.050017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.195497</td>\n",
       "      <td>0.013818</td>\n",
       "      <td>0.013932</td>\n",
       "      <td>0.363938</td>\n",
       "      <td>0.870485</td>\n",
       "      <td>0.078510</td>\n",
       "      <td>0.017714</td>\n",
       "      <td>0.860160</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.924495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018736</td>\n",
       "      <td>0.850831</td>\n",
       "      <td>0.661609</td>\n",
       "      <td>0.054414</td>\n",
       "      <td>0.588971</td>\n",
       "      <td>0.089557</td>\n",
       "      <td>0.067167</td>\n",
       "      <td>0.769726</td>\n",
       "      <td>0.938197</td>\n",
       "      <td>0.047651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.174768</td>\n",
       "      <td>0.067431</td>\n",
       "      <td>0.038313</td>\n",
       "      <td>0.505738</td>\n",
       "      <td>0.906744</td>\n",
       "      <td>0.247278</td>\n",
       "      <td>0.010073</td>\n",
       "      <td>0.797837</td>\n",
       "      <td>0.043061</td>\n",
       "      <td>0.853192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010022</td>\n",
       "      <td>0.832560</td>\n",
       "      <td>0.714355</td>\n",
       "      <td>0.061622</td>\n",
       "      <td>0.584559</td>\n",
       "      <td>0.206646</td>\n",
       "      <td>0.162174</td>\n",
       "      <td>0.851047</td>\n",
       "      <td>0.852246</td>\n",
       "      <td>0.014194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029307</td>\n",
       "      <td>0.121597</td>\n",
       "      <td>0.027090</td>\n",
       "      <td>0.754304</td>\n",
       "      <td>0.427342</td>\n",
       "      <td>0.080229</td>\n",
       "      <td>0.148663</td>\n",
       "      <td>0.929951</td>\n",
       "      <td>0.130745</td>\n",
       "      <td>0.877999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.927812</td>\n",
       "      <td>0.732418</td>\n",
       "      <td>0.250450</td>\n",
       "      <td>0.775368</td>\n",
       "      <td>0.077848</td>\n",
       "      <td>0.185815</td>\n",
       "      <td>0.779388</td>\n",
       "      <td>0.941743</td>\n",
       "      <td>0.278472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.308077</td>\n",
       "      <td>0.016996</td>\n",
       "      <td>0.112423</td>\n",
       "      <td>0.503624</td>\n",
       "      <td>0.746896</td>\n",
       "      <td>0.320344</td>\n",
       "      <td>0.012852</td>\n",
       "      <td>0.660572</td>\n",
       "      <td>0.063588</td>\n",
       "      <td>0.750983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018301</td>\n",
       "      <td>0.829115</td>\n",
       "      <td>0.653661</td>\n",
       "      <td>0.048649</td>\n",
       "      <td>0.645221</td>\n",
       "      <td>0.362975</td>\n",
       "      <td>0.463102</td>\n",
       "      <td>0.769189</td>\n",
       "      <td>0.821851</td>\n",
       "      <td>0.081784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0.263760</td>\n",
       "      <td>0.016858</td>\n",
       "      <td>0.060759</td>\n",
       "      <td>0.269405</td>\n",
       "      <td>0.776947</td>\n",
       "      <td>0.311748</td>\n",
       "      <td>0.007642</td>\n",
       "      <td>0.597476</td>\n",
       "      <td>0.033021</td>\n",
       "      <td>0.790565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.926913</td>\n",
       "      <td>0.658478</td>\n",
       "      <td>0.120360</td>\n",
       "      <td>0.605515</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.321918</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.842621</td>\n",
       "      <td>0.108145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>0.071122</td>\n",
       "      <td>0.022109</td>\n",
       "      <td>0.021478</td>\n",
       "      <td>0.662036</td>\n",
       "      <td>0.903499</td>\n",
       "      <td>0.107736</td>\n",
       "      <td>0.013546</td>\n",
       "      <td>0.789853</td>\n",
       "      <td>0.055332</td>\n",
       "      <td>0.926122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003050</td>\n",
       "      <td>0.682342</td>\n",
       "      <td>0.857418</td>\n",
       "      <td>0.008288</td>\n",
       "      <td>0.758456</td>\n",
       "      <td>0.254114</td>\n",
       "      <td>0.156209</td>\n",
       "      <td>0.900429</td>\n",
       "      <td>0.938703</td>\n",
       "      <td>0.041230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>0.020729</td>\n",
       "      <td>0.388697</td>\n",
       "      <td>0.043537</td>\n",
       "      <td>0.532770</td>\n",
       "      <td>0.927624</td>\n",
       "      <td>0.333238</td>\n",
       "      <td>0.281348</td>\n",
       "      <td>0.875612</td>\n",
       "      <td>0.575636</td>\n",
       "      <td>0.869595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.478867</td>\n",
       "      <td>0.906096</td>\n",
       "      <td>0.798651</td>\n",
       "      <td>0.425225</td>\n",
       "      <td>0.377206</td>\n",
       "      <td>0.415190</td>\n",
       "      <td>0.709898</td>\n",
       "      <td>0.964842</td>\n",
       "      <td>0.946471</td>\n",
       "      <td>0.412301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>0.080415</td>\n",
       "      <td>0.244576</td>\n",
       "      <td>0.062113</td>\n",
       "      <td>0.289792</td>\n",
       "      <td>0.962331</td>\n",
       "      <td>0.124642</td>\n",
       "      <td>0.120875</td>\n",
       "      <td>0.916044</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.880710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661438</td>\n",
       "      <td>0.881084</td>\n",
       "      <td>0.588150</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.738971</td>\n",
       "      <td>0.473418</td>\n",
       "      <td>0.144057</td>\n",
       "      <td>0.775899</td>\n",
       "      <td>0.927558</td>\n",
       "      <td>0.447786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>0.101144</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>0.016834</td>\n",
       "      <td>0.752794</td>\n",
       "      <td>0.965435</td>\n",
       "      <td>0.056734</td>\n",
       "      <td>0.013546</td>\n",
       "      <td>0.873294</td>\n",
       "      <td>0.098840</td>\n",
       "      <td>0.963942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010893</td>\n",
       "      <td>0.921372</td>\n",
       "      <td>0.688102</td>\n",
       "      <td>0.086126</td>\n",
       "      <td>0.540441</td>\n",
       "      <td>0.080380</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.900429</td>\n",
       "      <td>0.975515</td>\n",
       "      <td>0.023319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.4388849177984275  0.0971396987702086  0.1464783281733745  \\\n",
       "0              0.679056            0.018654            0.016060   \n",
       "1              0.195497            0.013818            0.013932   \n",
       "2              0.174768            0.067431            0.038313   \n",
       "3              0.029307            0.121597            0.027090   \n",
       "4              0.308077            0.016996            0.112423   \n",
       "..                  ...                 ...                 ...   \n",
       "453            0.263760            0.016858            0.060759   \n",
       "454            0.071122            0.022109            0.021478   \n",
       "455            0.020729            0.388697            0.043537   \n",
       "456            0.080415            0.244576            0.062113   \n",
       "457            0.101144            0.013542            0.016834   \n",
       "\n",
       "     0.3202959830866808  0.7835778781038374  0.1506017191977076  \\\n",
       "0              0.593929            0.876552            0.129513   \n",
       "1              0.363938            0.870485            0.078510   \n",
       "2              0.505738            0.906744            0.247278   \n",
       "3              0.754304            0.427342            0.080229   \n",
       "4              0.503624            0.746896            0.320344   \n",
       "..                  ...                 ...                 ...   \n",
       "453            0.269405            0.776947            0.311748   \n",
       "454            0.662036            0.903499            0.107736   \n",
       "455            0.532770            0.927624            0.333238   \n",
       "456            0.289792            0.962331            0.124642   \n",
       "457            0.752794            0.965435            0.056734   \n",
       "\n",
       "     0.1820076415422022  0.1053309296935359  0.1597501115573404  \\\n",
       "0              0.020493            0.895957            0.035029   \n",
       "1              0.017714            0.860160            0.055556   \n",
       "2              0.010073            0.797837            0.043061   \n",
       "3              0.148663            0.929951            0.130745   \n",
       "4              0.012852            0.660572            0.063588   \n",
       "..                  ...                 ...                 ...   \n",
       "453            0.007642            0.597476            0.033021   \n",
       "454            0.013546            0.789853            0.055332   \n",
       "455            0.281348            0.875612            0.575636   \n",
       "456            0.120875            0.916044            0.129630   \n",
       "457            0.013546            0.873294            0.098840   \n",
       "\n",
       "     0.7057069269350684  ...  0.1938997821350765  0.7852328890220159  \\\n",
       "0              0.925173  ...            0.019608            0.926764   \n",
       "1              0.924495  ...            0.018736            0.850831   \n",
       "2              0.853192  ...            0.010022            0.832560   \n",
       "3              0.877999  ...            0.223529            0.927812   \n",
       "4              0.750983  ...            0.018301            0.829115   \n",
       "..                  ...  ...                 ...                 ...   \n",
       "453            0.790565  ...            0.006100            0.926913   \n",
       "454            0.926122  ...            0.003050            0.682342   \n",
       "455            0.869595  ...            0.478867            0.906096   \n",
       "456            0.880710  ...            0.661438            0.881084   \n",
       "457            0.963942  ...            0.010893            0.921372   \n",
       "\n",
       "     0.3521194605009633  0.2169369369369371  0.8426470588235293  \\\n",
       "0              0.204239            0.061622            0.662500   \n",
       "1              0.661609            0.054414            0.588971   \n",
       "2              0.714355            0.061622            0.584559   \n",
       "3              0.732418            0.250450            0.775368   \n",
       "4              0.653661            0.048649            0.645221   \n",
       "..                  ...                 ...                 ...   \n",
       "453            0.658478            0.120360            0.605515   \n",
       "454            0.857418            0.008288            0.758456   \n",
       "455            0.798651            0.425225            0.377206   \n",
       "456            0.588150            0.453333            0.738971   \n",
       "457            0.688102            0.086126            0.540441   \n",
       "\n",
       "     0.228607594936709  0.2920901458241273  0.7171229200214708.1  \\\n",
       "0             0.131329            0.093239              0.856414   \n",
       "1             0.089557            0.067167              0.769726   \n",
       "2             0.206646            0.162174              0.851047   \n",
       "3             0.077848            0.185815              0.779388   \n",
       "4             0.362975            0.463102              0.769189   \n",
       "..                 ...                 ...                   ...   \n",
       "453           0.325000            0.321918              0.530864   \n",
       "454           0.254114            0.156209              0.900429   \n",
       "455           0.415190            0.709898              0.964842   \n",
       "456           0.473418            0.144057              0.775899   \n",
       "457           0.080380            0.041096              0.900429   \n",
       "\n",
       "     0.82016210739615  0.1997296383913485  \n",
       "0            0.959642            0.050017  \n",
       "1            0.938197            0.047651  \n",
       "2            0.852246            0.014194  \n",
       "3            0.941743            0.278472  \n",
       "4            0.821851            0.081784  \n",
       "..                ...                 ...  \n",
       "453          0.842621            0.108145  \n",
       "454          0.938703            0.041230  \n",
       "455          0.946471            0.412301  \n",
       "456          0.927558            0.447786  \n",
       "457          0.975515            0.023319  \n",
       "\n",
       "[458 rows x 65 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取制表符分隔的CSV文件\n",
    "Methylation_train = pd.read_csv('../../DATA/BRCA_survival/1_tr.csv')\n",
    "# 显示 DataFrame\n",
    "Methylation_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96898d81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:37.045657Z",
     "iopub.status.busy": "2025-05-09T13:27:37.045279Z",
     "iopub.status.idle": "2025-05-09T13:27:37.061978Z",
     "shell.execute_reply": "2025-05-09T13:27:37.061537Z"
    },
    "papermill": {
     "duration": 0.043366,
     "end_time": "2025-05-09T13:27:37.062668",
     "exception": false,
     "start_time": "2025-05-09T13:27:37.019302",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.6072194424588993</th>\n",
       "      <th>0.1258808898714937</th>\n",
       "      <th>0.1484133126934984</th>\n",
       "      <th>0.2156448202959832</th>\n",
       "      <th>0.774971783295711</th>\n",
       "      <th>0.5249283667621776</th>\n",
       "      <th>0.168808614102119</th>\n",
       "      <th>0.6294102498068503</th>\n",
       "      <th>0.0680499776885317</th>\n",
       "      <th>0.7741629388640369</th>\n",
       "      <th>...</th>\n",
       "      <th>0.4535947712418302</th>\n",
       "      <th>0.3741201138235735</th>\n",
       "      <th>0.3660886319845857</th>\n",
       "      <th>0.3030630630630631</th>\n",
       "      <th>0.4352941176470588</th>\n",
       "      <th>0.5389240506329114</th>\n",
       "      <th>0.7631462660185595</th>\n",
       "      <th>0.5974235104669887.1</th>\n",
       "      <th>0.7700101317122594</th>\n",
       "      <th>0.1841838458938831</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.626162</td>\n",
       "      <td>0.013680</td>\n",
       "      <td>0.013545</td>\n",
       "      <td>0.482785</td>\n",
       "      <td>0.971924</td>\n",
       "      <td>0.114040</td>\n",
       "      <td>0.014936</td>\n",
       "      <td>0.952614</td>\n",
       "      <td>0.019857</td>\n",
       "      <td>0.968822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010458</td>\n",
       "      <td>0.703460</td>\n",
       "      <td>0.381262</td>\n",
       "      <td>0.057658</td>\n",
       "      <td>0.629044</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.070482</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.944107</td>\n",
       "      <td>0.037513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.040386</td>\n",
       "      <td>0.242089</td>\n",
       "      <td>0.036765</td>\n",
       "      <td>0.886741</td>\n",
       "      <td>0.036964</td>\n",
       "      <td>0.012321</td>\n",
       "      <td>0.215353</td>\n",
       "      <td>0.858357</td>\n",
       "      <td>0.180946</td>\n",
       "      <td>0.965162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572985</td>\n",
       "      <td>0.797214</td>\n",
       "      <td>0.783237</td>\n",
       "      <td>0.420901</td>\n",
       "      <td>0.749265</td>\n",
       "      <td>0.152532</td>\n",
       "      <td>0.252983</td>\n",
       "      <td>0.918948</td>\n",
       "      <td>0.977710</td>\n",
       "      <td>0.427509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039671</td>\n",
       "      <td>0.120492</td>\n",
       "      <td>0.041602</td>\n",
       "      <td>0.311235</td>\n",
       "      <td>0.851157</td>\n",
       "      <td>0.177650</td>\n",
       "      <td>0.026745</td>\n",
       "      <td>0.840845</td>\n",
       "      <td>0.170683</td>\n",
       "      <td>0.838688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095425</td>\n",
       "      <td>0.743747</td>\n",
       "      <td>0.683767</td>\n",
       "      <td>0.134775</td>\n",
       "      <td>0.350735</td>\n",
       "      <td>0.156962</td>\n",
       "      <td>0.250994</td>\n",
       "      <td>0.505099</td>\n",
       "      <td>0.909659</td>\n",
       "      <td>0.288273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.443531</td>\n",
       "      <td>0.168716</td>\n",
       "      <td>0.073297</td>\n",
       "      <td>0.471912</td>\n",
       "      <td>0.663318</td>\n",
       "      <td>0.308138</td>\n",
       "      <td>0.077457</td>\n",
       "      <td>0.136750</td>\n",
       "      <td>0.126952</td>\n",
       "      <td>0.727504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132898</td>\n",
       "      <td>0.775348</td>\n",
       "      <td>0.548892</td>\n",
       "      <td>0.449369</td>\n",
       "      <td>0.730882</td>\n",
       "      <td>0.305380</td>\n",
       "      <td>0.318294</td>\n",
       "      <td>0.350778</td>\n",
       "      <td>0.461837</td>\n",
       "      <td>0.156472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.283059</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.054954</td>\n",
       "      <td>0.301873</td>\n",
       "      <td>0.895034</td>\n",
       "      <td>0.194269</td>\n",
       "      <td>0.016325</td>\n",
       "      <td>0.881535</td>\n",
       "      <td>0.071843</td>\n",
       "      <td>0.936424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016558</td>\n",
       "      <td>0.737008</td>\n",
       "      <td>0.635597</td>\n",
       "      <td>0.098739</td>\n",
       "      <td>0.748162</td>\n",
       "      <td>0.188291</td>\n",
       "      <td>0.242156</td>\n",
       "      <td>0.918680</td>\n",
       "      <td>0.971125</td>\n",
       "      <td>0.104765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.586133</td>\n",
       "      <td>0.101009</td>\n",
       "      <td>0.265867</td>\n",
       "      <td>0.211265</td>\n",
       "      <td>0.485609</td>\n",
       "      <td>0.743266</td>\n",
       "      <td>0.302883</td>\n",
       "      <td>0.166109</td>\n",
       "      <td>0.104641</td>\n",
       "      <td>0.481497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397386</td>\n",
       "      <td>0.558784</td>\n",
       "      <td>0.288054</td>\n",
       "      <td>0.295135</td>\n",
       "      <td>0.488603</td>\n",
       "      <td>0.693987</td>\n",
       "      <td>0.776845</td>\n",
       "      <td>0.385132</td>\n",
       "      <td>0.381966</td>\n",
       "      <td>0.339642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.049678</td>\n",
       "      <td>0.068813</td>\n",
       "      <td>0.020704</td>\n",
       "      <td>0.270160</td>\n",
       "      <td>0.496473</td>\n",
       "      <td>0.046132</td>\n",
       "      <td>0.109413</td>\n",
       "      <td>0.903940</td>\n",
       "      <td>0.077644</td>\n",
       "      <td>0.474448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.450651</td>\n",
       "      <td>0.768304</td>\n",
       "      <td>0.244685</td>\n",
       "      <td>0.705515</td>\n",
       "      <td>0.054747</td>\n",
       "      <td>0.240168</td>\n",
       "      <td>0.772410</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.012152</td>\n",
       "      <td>0.267100</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>0.448203</td>\n",
       "      <td>0.918030</td>\n",
       "      <td>0.044126</td>\n",
       "      <td>0.179576</td>\n",
       "      <td>0.837239</td>\n",
       "      <td>0.111780</td>\n",
       "      <td>0.861326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474946</td>\n",
       "      <td>0.824023</td>\n",
       "      <td>0.672447</td>\n",
       "      <td>0.365405</td>\n",
       "      <td>0.653676</td>\n",
       "      <td>0.099684</td>\n",
       "      <td>0.139638</td>\n",
       "      <td>0.750671</td>\n",
       "      <td>0.885849</td>\n",
       "      <td>0.381210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.072909</td>\n",
       "      <td>0.023490</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.526276</td>\n",
       "      <td>0.707534</td>\n",
       "      <td>0.362464</td>\n",
       "      <td>0.016672</td>\n",
       "      <td>0.807881</td>\n",
       "      <td>0.062472</td>\n",
       "      <td>0.897248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>0.685338</td>\n",
       "      <td>0.754094</td>\n",
       "      <td>0.073874</td>\n",
       "      <td>0.652206</td>\n",
       "      <td>0.569620</td>\n",
       "      <td>0.238400</td>\n",
       "      <td>0.772410</td>\n",
       "      <td>0.944613</td>\n",
       "      <td>0.087192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.047891</td>\n",
       "      <td>0.236009</td>\n",
       "      <td>0.034443</td>\n",
       "      <td>0.449260</td>\n",
       "      <td>0.922968</td>\n",
       "      <td>0.150143</td>\n",
       "      <td>0.531087</td>\n",
       "      <td>0.858099</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.891555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974292</td>\n",
       "      <td>0.779392</td>\n",
       "      <td>0.816233</td>\n",
       "      <td>0.637838</td>\n",
       "      <td>0.815809</td>\n",
       "      <td>0.095253</td>\n",
       "      <td>0.190676</td>\n",
       "      <td>0.885132</td>\n",
       "      <td>0.950017</td>\n",
       "      <td>0.742819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.6072194424588993  0.1258808898714937  0.1484133126934984  \\\n",
       "0              0.626162            0.013680            0.013545   \n",
       "1              0.040386            0.242089            0.036765   \n",
       "2              0.039671            0.120492            0.041602   \n",
       "3              0.443531            0.168716            0.073297   \n",
       "4              0.283059            0.006494            0.054954   \n",
       "..                  ...                 ...                 ...   \n",
       "147            0.586133            0.101009            0.265867   \n",
       "148            0.049678            0.068813            0.020704   \n",
       "149            0.012152            0.267100            0.022059   \n",
       "150            0.072909            0.023490            0.052632   \n",
       "151            0.047891            0.236009            0.034443   \n",
       "\n",
       "     0.2156448202959832  0.774971783295711  0.5249283667621776  \\\n",
       "0              0.482785           0.971924            0.114040   \n",
       "1              0.886741           0.036964            0.012321   \n",
       "2              0.311235           0.851157            0.177650   \n",
       "3              0.471912           0.663318            0.308138   \n",
       "4              0.301873           0.895034            0.194269   \n",
       "..                  ...                ...                 ...   \n",
       "147            0.211265           0.485609            0.743266   \n",
       "148            0.270160           0.496473            0.046132   \n",
       "149            0.448203           0.918030            0.044126   \n",
       "150            0.526276           0.707534            0.362464   \n",
       "151            0.449260           0.922968            0.150143   \n",
       "\n",
       "     0.168808614102119  0.6294102498068503  0.0680499776885317  \\\n",
       "0             0.014936            0.952614            0.019857   \n",
       "1             0.215353            0.858357            0.180946   \n",
       "2             0.026745            0.840845            0.170683   \n",
       "3             0.077457            0.136750            0.126952   \n",
       "4             0.016325            0.881535            0.071843   \n",
       "..                 ...                 ...                 ...   \n",
       "147           0.302883            0.166109            0.104641   \n",
       "148           0.109413            0.903940            0.077644   \n",
       "149           0.179576            0.837239            0.111780   \n",
       "150           0.016672            0.807881            0.062472   \n",
       "151           0.531087            0.858099            0.259259   \n",
       "\n",
       "     0.7741629388640369  ...  0.4535947712418302  0.3741201138235735  \\\n",
       "0              0.968822  ...            0.010458            0.703460   \n",
       "1              0.965162  ...            0.572985            0.797214   \n",
       "2              0.838688  ...            0.095425            0.743747   \n",
       "3              0.727504  ...            0.132898            0.775348   \n",
       "4              0.936424  ...            0.016558            0.737008   \n",
       "..                  ...  ...                 ...                 ...   \n",
       "147            0.481497  ...            0.397386            0.558784   \n",
       "148            0.474448  ...            0.192157            0.450651   \n",
       "149            0.861326  ...            0.474946            0.824023   \n",
       "150            0.897248  ...            0.002614            0.685338   \n",
       "151            0.891555  ...            0.974292            0.779392   \n",
       "\n",
       "     0.3660886319845857  0.3030630630630631  0.4352941176470588  \\\n",
       "0              0.381262            0.057658            0.629044   \n",
       "1              0.783237            0.420901            0.749265   \n",
       "2              0.683767            0.134775            0.350735   \n",
       "3              0.548892            0.449369            0.730882   \n",
       "4              0.635597            0.098739            0.748162   \n",
       "..                  ...                 ...                 ...   \n",
       "147            0.288054            0.295135            0.488603   \n",
       "148            0.768304            0.244685            0.705515   \n",
       "149            0.672447            0.365405            0.653676   \n",
       "150            0.754094            0.073874            0.652206   \n",
       "151            0.816233            0.637838            0.815809   \n",
       "\n",
       "     0.5389240506329114  0.7631462660185595  0.5974235104669887.1  \\\n",
       "0              0.075949            0.070482              0.833333   \n",
       "1              0.152532            0.252983              0.918948   \n",
       "2              0.156962            0.250994              0.505099   \n",
       "3              0.305380            0.318294              0.350778   \n",
       "4              0.188291            0.242156              0.918680   \n",
       "..                  ...                 ...                   ...   \n",
       "147            0.693987            0.776845              0.385132   \n",
       "148            0.054747            0.240168              0.772410   \n",
       "149            0.099684            0.139638              0.750671   \n",
       "150            0.569620            0.238400              0.772410   \n",
       "151            0.095253            0.190676              0.885132   \n",
       "\n",
       "     0.7700101317122594  0.1841838458938831  \n",
       "0              0.944107            0.037513  \n",
       "1              0.977710            0.427509  \n",
       "2              0.909659            0.288273  \n",
       "3              0.461837            0.156472  \n",
       "4              0.971125            0.104765  \n",
       "..                  ...                 ...  \n",
       "147            0.381966            0.339642  \n",
       "148            0.952381            0.090909  \n",
       "149            0.885849            0.381210  \n",
       "150            0.944613            0.087192  \n",
       "151            0.950017            0.742819  \n",
       "\n",
       "[152 rows x 65 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取制表符分隔的CSV文件\n",
    "Methylation_test = pd.read_csv('../../DATA/BRCA_survival/1_te.csv')\n",
    "# 显示 DataFrame\n",
    "Methylation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "658d5fc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:37.084520Z",
     "iopub.status.busy": "2025-05-09T13:27:37.084181Z",
     "iopub.status.idle": "2025-05-09T13:27:37.086452Z",
     "shell.execute_reply": "2025-05-09T13:27:37.086013Z"
    },
    "papermill": {
     "duration": 0.018907,
     "end_time": "2025-05-09T13:27:37.087065",
     "exception": false,
     "start_time": "2025-05-09T13:27:37.068158",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 读取制表符分隔的CSV文件\n",
    "# Methylation_val = pd.read_csv('../../DATA/BRCA_survival/methylation_val.csv')\n",
    "# # 显示 DataFrame\n",
    "# Methylation_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04e4836d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:37.111339Z",
     "iopub.status.busy": "2025-05-09T13:27:37.110866Z",
     "iopub.status.idle": "2025-05-09T13:27:37.132278Z",
     "shell.execute_reply": "2025-05-09T13:27:37.131784Z"
    },
    "papermill": {
     "duration": 0.036453,
     "end_time": "2025-05-09T13:27:37.133008",
     "exception": false,
     "start_time": "2025-05-09T13:27:37.096555",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.4170409817087287</th>\n",
       "      <th>0.359123085618927</th>\n",
       "      <th>0.4652716142099635</th>\n",
       "      <th>0.3541872988363455</th>\n",
       "      <th>0.5325353012958335</th>\n",
       "      <th>0.2918074834037416</th>\n",
       "      <th>0.4241145709531734</th>\n",
       "      <th>0.6050296627810159</th>\n",
       "      <th>0.3337271785575554</th>\n",
       "      <th>0.5429385588258255</th>\n",
       "      <th>...</th>\n",
       "      <th>0.3857058823529412</th>\n",
       "      <th>0.2456376192735514</th>\n",
       "      <th>0.3108428254648143</th>\n",
       "      <th>0.3093764280669686</th>\n",
       "      <th>0.328096769929053</th>\n",
       "      <th>0.3393195249297149</th>\n",
       "      <th>0.2900004403152657</th>\n",
       "      <th>0.5289970599196654</th>\n",
       "      <th>0.5720433841065049</th>\n",
       "      <th>0.0944722685958078</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.424763</td>\n",
       "      <td>0.370401</td>\n",
       "      <td>0.333037</td>\n",
       "      <td>0.517269</td>\n",
       "      <td>0.503760</td>\n",
       "      <td>0.281518</td>\n",
       "      <td>0.527068</td>\n",
       "      <td>0.523808</td>\n",
       "      <td>0.315260</td>\n",
       "      <td>0.607216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154618</td>\n",
       "      <td>0.266540</td>\n",
       "      <td>0.449576</td>\n",
       "      <td>0.373825</td>\n",
       "      <td>0.456782</td>\n",
       "      <td>0.451718</td>\n",
       "      <td>0.161094</td>\n",
       "      <td>0.378225</td>\n",
       "      <td>0.567036</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.546620</td>\n",
       "      <td>0.525651</td>\n",
       "      <td>0.517967</td>\n",
       "      <td>0.528952</td>\n",
       "      <td>0.498693</td>\n",
       "      <td>0.247646</td>\n",
       "      <td>0.599744</td>\n",
       "      <td>0.711894</td>\n",
       "      <td>0.407436</td>\n",
       "      <td>0.734184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294618</td>\n",
       "      <td>0.399889</td>\n",
       "      <td>0.532608</td>\n",
       "      <td>0.327531</td>\n",
       "      <td>0.573646</td>\n",
       "      <td>0.391474</td>\n",
       "      <td>0.354806</td>\n",
       "      <td>0.696157</td>\n",
       "      <td>0.714321</td>\n",
       "      <td>0.035819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.420109</td>\n",
       "      <td>0.347173</td>\n",
       "      <td>0.476605</td>\n",
       "      <td>0.517362</td>\n",
       "      <td>0.411726</td>\n",
       "      <td>0.798386</td>\n",
       "      <td>0.457051</td>\n",
       "      <td>0.652568</td>\n",
       "      <td>0.420028</td>\n",
       "      <td>0.639798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418412</td>\n",
       "      <td>0.439269</td>\n",
       "      <td>0.543657</td>\n",
       "      <td>0.359367</td>\n",
       "      <td>0.494348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483290</td>\n",
       "      <td>0.532331</td>\n",
       "      <td>0.680686</td>\n",
       "      <td>0.336858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.346064</td>\n",
       "      <td>0.462331</td>\n",
       "      <td>0.737512</td>\n",
       "      <td>0.448549</td>\n",
       "      <td>0.643640</td>\n",
       "      <td>0.376992</td>\n",
       "      <td>0.423505</td>\n",
       "      <td>0.683701</td>\n",
       "      <td>0.351159</td>\n",
       "      <td>0.540505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461647</td>\n",
       "      <td>0.567531</td>\n",
       "      <td>0.276538</td>\n",
       "      <td>0.167449</td>\n",
       "      <td>0.330454</td>\n",
       "      <td>0.418584</td>\n",
       "      <td>0.307499</td>\n",
       "      <td>0.466469</td>\n",
       "      <td>0.536262</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.460963</td>\n",
       "      <td>0.347926</td>\n",
       "      <td>0.282492</td>\n",
       "      <td>0.397948</td>\n",
       "      <td>0.624754</td>\n",
       "      <td>0.414922</td>\n",
       "      <td>0.617468</td>\n",
       "      <td>0.524563</td>\n",
       "      <td>0.392416</td>\n",
       "      <td>0.527962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387382</td>\n",
       "      <td>0.490906</td>\n",
       "      <td>0.405701</td>\n",
       "      <td>0.331741</td>\n",
       "      <td>0.445071</td>\n",
       "      <td>0.395175</td>\n",
       "      <td>0.089895</td>\n",
       "      <td>0.572508</td>\n",
       "      <td>0.572144</td>\n",
       "      <td>0.027101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0.558740</td>\n",
       "      <td>0.646987</td>\n",
       "      <td>0.325095</td>\n",
       "      <td>0.733242</td>\n",
       "      <td>0.441002</td>\n",
       "      <td>0.381005</td>\n",
       "      <td>0.685257</td>\n",
       "      <td>0.600151</td>\n",
       "      <td>0.483329</td>\n",
       "      <td>0.569365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277500</td>\n",
       "      <td>0.434841</td>\n",
       "      <td>0.422739</td>\n",
       "      <td>0.559622</td>\n",
       "      <td>0.479179</td>\n",
       "      <td>0.523065</td>\n",
       "      <td>0.447994</td>\n",
       "      <td>0.584507</td>\n",
       "      <td>0.590090</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>0.513834</td>\n",
       "      <td>0.480997</td>\n",
       "      <td>0.479791</td>\n",
       "      <td>0.399000</td>\n",
       "      <td>0.491510</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.558890</td>\n",
       "      <td>0.579777</td>\n",
       "      <td>0.453758</td>\n",
       "      <td>0.535431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145147</td>\n",
       "      <td>0.379250</td>\n",
       "      <td>0.359115</td>\n",
       "      <td>0.254954</td>\n",
       "      <td>0.486813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380758</td>\n",
       "      <td>0.601640</td>\n",
       "      <td>0.618900</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>0.272829</td>\n",
       "      <td>0.838667</td>\n",
       "      <td>0.880157</td>\n",
       "      <td>0.537881</td>\n",
       "      <td>0.996920</td>\n",
       "      <td>0.810969</td>\n",
       "      <td>0.500371</td>\n",
       "      <td>0.602506</td>\n",
       "      <td>0.301453</td>\n",
       "      <td>0.433823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547794</td>\n",
       "      <td>0.618008</td>\n",
       "      <td>0.502075</td>\n",
       "      <td>0.125988</td>\n",
       "      <td>0.267847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292272</td>\n",
       "      <td>0.355211</td>\n",
       "      <td>0.485741</td>\n",
       "      <td>0.491393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>0.549282</td>\n",
       "      <td>0.646368</td>\n",
       "      <td>0.587276</td>\n",
       "      <td>0.716839</td>\n",
       "      <td>0.485897</td>\n",
       "      <td>0.682031</td>\n",
       "      <td>0.697751</td>\n",
       "      <td>0.770035</td>\n",
       "      <td>0.566166</td>\n",
       "      <td>0.691766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511765</td>\n",
       "      <td>0.558306</td>\n",
       "      <td>0.651384</td>\n",
       "      <td>0.642059</td>\n",
       "      <td>0.635053</td>\n",
       "      <td>0.436686</td>\n",
       "      <td>0.659636</td>\n",
       "      <td>0.585200</td>\n",
       "      <td>0.757595</td>\n",
       "      <td>0.176813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>0.482565</td>\n",
       "      <td>0.371222</td>\n",
       "      <td>0.383548</td>\n",
       "      <td>0.374025</td>\n",
       "      <td>0.472787</td>\n",
       "      <td>0.199049</td>\n",
       "      <td>0.709784</td>\n",
       "      <td>0.530040</td>\n",
       "      <td>0.471060</td>\n",
       "      <td>0.490280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148941</td>\n",
       "      <td>0.413148</td>\n",
       "      <td>0.269772</td>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.478848</td>\n",
       "      <td>0.682770</td>\n",
       "      <td>0.308282</td>\n",
       "      <td>0.605418</td>\n",
       "      <td>0.605778</td>\n",
       "      <td>0.163346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.4170409817087287  0.359123085618927  0.4652716142099635  \\\n",
       "0              0.424763           0.370401            0.333037   \n",
       "1              0.546620           0.525651            0.517967   \n",
       "2              0.420109           0.347173            0.476605   \n",
       "3              0.346064           0.462331            0.737512   \n",
       "4              0.460963           0.347926            0.282492   \n",
       "..                  ...                ...                 ...   \n",
       "453            0.558740           0.646987            0.325095   \n",
       "454            0.513834           0.480997            0.479791   \n",
       "455            0.272829           0.838667            0.880157   \n",
       "456            0.549282           0.646368            0.587276   \n",
       "457            0.482565           0.371222            0.383548   \n",
       "\n",
       "     0.3541872988363455  0.5325353012958335  0.2918074834037416  \\\n",
       "0              0.517269            0.503760            0.281518   \n",
       "1              0.528952            0.498693            0.247646   \n",
       "2              0.517362            0.411726            0.798386   \n",
       "3              0.448549            0.643640            0.376992   \n",
       "4              0.397948            0.624754            0.414922   \n",
       "..                  ...                 ...                 ...   \n",
       "453            0.733242            0.441002            0.381005   \n",
       "454            0.399000            0.491510            0.325000   \n",
       "455            0.537881            0.996920            0.810969   \n",
       "456            0.716839            0.485897            0.682031   \n",
       "457            0.374025            0.472787            0.199049   \n",
       "\n",
       "     0.4241145709531734  0.6050296627810159  0.3337271785575554  \\\n",
       "0              0.527068            0.523808            0.315260   \n",
       "1              0.599744            0.711894            0.407436   \n",
       "2              0.457051            0.652568            0.420028   \n",
       "3              0.423505            0.683701            0.351159   \n",
       "4              0.617468            0.524563            0.392416   \n",
       "..                  ...                 ...                 ...   \n",
       "453            0.685257            0.600151            0.483329   \n",
       "454            0.558890            0.579777            0.453758   \n",
       "455            0.500371            0.602506            0.301453   \n",
       "456            0.697751            0.770035            0.566166   \n",
       "457            0.709784            0.530040            0.471060   \n",
       "\n",
       "     0.5429385588258255  ...  0.3857058823529412  0.2456376192735514  \\\n",
       "0              0.607216  ...            0.154618            0.266540   \n",
       "1              0.734184  ...            0.294618            0.399889   \n",
       "2              0.639798  ...            0.418412            0.439269   \n",
       "3              0.540505  ...            0.461647            0.567531   \n",
       "4              0.527962  ...            0.387382            0.490906   \n",
       "..                  ...  ...                 ...                 ...   \n",
       "453            0.569365  ...            0.277500            0.434841   \n",
       "454            0.535431  ...            0.145147            0.379250   \n",
       "455            0.433823  ...            0.547794            0.618008   \n",
       "456            0.691766  ...            0.511765            0.558306   \n",
       "457            0.490280  ...            0.148941            0.413148   \n",
       "\n",
       "     0.3108428254648143  0.3093764280669686  0.328096769929053  \\\n",
       "0              0.449576            0.373825           0.456782   \n",
       "1              0.532608            0.327531           0.573646   \n",
       "2              0.543657            0.359367           0.494348   \n",
       "3              0.276538            0.167449           0.330454   \n",
       "4              0.405701            0.331741           0.445071   \n",
       "..                  ...                 ...                ...   \n",
       "453            0.422739            0.559622           0.479179   \n",
       "454            0.359115            0.254954           0.486813   \n",
       "455            0.502075            0.125988           0.267847   \n",
       "456            0.651384            0.642059           0.635053   \n",
       "457            0.269772            0.294379           0.478848   \n",
       "\n",
       "     0.3393195249297149  0.2900004403152657  0.5289970599196654  \\\n",
       "0              0.451718            0.161094            0.378225   \n",
       "1              0.391474            0.354806            0.696157   \n",
       "2              0.000000            0.483290            0.532331   \n",
       "3              0.418584            0.307499            0.466469   \n",
       "4              0.395175            0.089895            0.572508   \n",
       "..                  ...                 ...                 ...   \n",
       "453            0.523065            0.447994            0.584507   \n",
       "454            0.000000            0.380758            0.601640   \n",
       "455            0.000000            0.292272            0.355211   \n",
       "456            0.436686            0.659636            0.585200   \n",
       "457            0.682770            0.308282            0.605418   \n",
       "\n",
       "     0.5720433841065049  0.0944722685958078  \n",
       "0              0.567036            0.000000  \n",
       "1              0.714321            0.035819  \n",
       "2              0.680686            0.336858  \n",
       "3              0.536262            0.000000  \n",
       "4              0.572144            0.027101  \n",
       "..                  ...                 ...  \n",
       "453            0.590090            0.000000  \n",
       "454            0.618900            0.000000  \n",
       "455            0.485741            0.491393  \n",
       "456            0.757595            0.176813  \n",
       "457            0.605778            0.163346  \n",
       "\n",
       "[458 rows x 49 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取制表符分隔的CSV文件\n",
    "miRNASeq_train = pd.read_csv('../../DATA/BRCA_survival/3_tr.csv')\n",
    "# 显示 DataFrame\n",
    "miRNASeq_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f744b2a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:37.143490Z",
     "iopub.status.busy": "2025-05-09T13:27:37.143121Z",
     "iopub.status.idle": "2025-05-09T13:27:37.159930Z",
     "shell.execute_reply": "2025-05-09T13:27:37.159437Z"
    },
    "papermill": {
     "duration": 0.022756,
     "end_time": "2025-05-09T13:27:37.160628",
     "exception": false,
     "start_time": "2025-05-09T13:27:37.137872",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1176082426487613</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.2269748071277395</th>\n",
       "      <th>0.2412416439712801</th>\n",
       "      <th>0.0912197106165378</th>\n",
       "      <th>0.5104254677127338</th>\n",
       "      <th>0.0.1</th>\n",
       "      <th>0.1521908825978353</th>\n",
       "      <th>0.1751909879580474</th>\n",
       "      <th>0.2727118952819632</th>\n",
       "      <th>...</th>\n",
       "      <th>0.3183529411764706</th>\n",
       "      <th>0.3172808266118401</th>\n",
       "      <th>0.2419119458711597</th>\n",
       "      <th>0.1928461634331768</th>\n",
       "      <th>0.4037368351474023</th>\n",
       "      <th>0.1411440702277813</th>\n",
       "      <th>0.4453436660649024</th>\n",
       "      <th>0.2916373348792911</th>\n",
       "      <th>0.4124779561590263</th>\n",
       "      <th>0.2477462437395659</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.441943</td>\n",
       "      <td>0.572551</td>\n",
       "      <td>0.350845</td>\n",
       "      <td>0.442498</td>\n",
       "      <td>0.455483</td>\n",
       "      <td>0.465932</td>\n",
       "      <td>0.567640</td>\n",
       "      <td>0.541632</td>\n",
       "      <td>0.303800</td>\n",
       "      <td>0.601140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201412</td>\n",
       "      <td>0.281275</td>\n",
       "      <td>0.283722</td>\n",
       "      <td>0.416615</td>\n",
       "      <td>0.363879</td>\n",
       "      <td>0.446899</td>\n",
       "      <td>0.316261</td>\n",
       "      <td>0.508924</td>\n",
       "      <td>0.511353</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.056807</td>\n",
       "      <td>0.178909</td>\n",
       "      <td>0.472918</td>\n",
       "      <td>0.448997</td>\n",
       "      <td>0.293800</td>\n",
       "      <td>0.538865</td>\n",
       "      <td>0.373915</td>\n",
       "      <td>0.351504</td>\n",
       "      <td>0.125793</td>\n",
       "      <td>0.334049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376324</td>\n",
       "      <td>0.472323</td>\n",
       "      <td>0.280007</td>\n",
       "      <td>0.107626</td>\n",
       "      <td>0.140958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405398</td>\n",
       "      <td>0.256512</td>\n",
       "      <td>0.393719</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.369264</td>\n",
       "      <td>0.499825</td>\n",
       "      <td>0.546073</td>\n",
       "      <td>0.686417</td>\n",
       "      <td>0.430879</td>\n",
       "      <td>0.499019</td>\n",
       "      <td>0.360382</td>\n",
       "      <td>0.801572</td>\n",
       "      <td>0.259258</td>\n",
       "      <td>0.715122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348206</td>\n",
       "      <td>0.242185</td>\n",
       "      <td>0.399276</td>\n",
       "      <td>0.391744</td>\n",
       "      <td>0.500991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.402924</td>\n",
       "      <td>0.493613</td>\n",
       "      <td>0.676995</td>\n",
       "      <td>0.151771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.517284</td>\n",
       "      <td>0.455724</td>\n",
       "      <td>0.306775</td>\n",
       "      <td>0.467582</td>\n",
       "      <td>0.338625</td>\n",
       "      <td>0.616611</td>\n",
       "      <td>0.516461</td>\n",
       "      <td>0.661558</td>\n",
       "      <td>0.350285</td>\n",
       "      <td>0.636688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231471</td>\n",
       "      <td>0.293848</td>\n",
       "      <td>0.391866</td>\n",
       "      <td>0.271987</td>\n",
       "      <td>0.495681</td>\n",
       "      <td>0.225773</td>\n",
       "      <td>0.346854</td>\n",
       "      <td>0.600781</td>\n",
       "      <td>0.606043</td>\n",
       "      <td>0.036264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.316393</td>\n",
       "      <td>0.249320</td>\n",
       "      <td>0.452914</td>\n",
       "      <td>0.342179</td>\n",
       "      <td>0.333000</td>\n",
       "      <td>0.442517</td>\n",
       "      <td>0.372474</td>\n",
       "      <td>0.461386</td>\n",
       "      <td>0.411272</td>\n",
       "      <td>0.397715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308941</td>\n",
       "      <td>0.359850</td>\n",
       "      <td>0.174440</td>\n",
       "      <td>0.260189</td>\n",
       "      <td>0.310856</td>\n",
       "      <td>0.126370</td>\n",
       "      <td>0.266021</td>\n",
       "      <td>0.422026</td>\n",
       "      <td>0.489899</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.529648</td>\n",
       "      <td>0.381934</td>\n",
       "      <td>0.229728</td>\n",
       "      <td>0.376578</td>\n",
       "      <td>0.375803</td>\n",
       "      <td>0.329692</td>\n",
       "      <td>0.570968</td>\n",
       "      <td>0.603013</td>\n",
       "      <td>0.323449</td>\n",
       "      <td>0.644612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378118</td>\n",
       "      <td>0.373926</td>\n",
       "      <td>0.531717</td>\n",
       "      <td>0.401756</td>\n",
       "      <td>0.523840</td>\n",
       "      <td>0.278214</td>\n",
       "      <td>0.292651</td>\n",
       "      <td>0.601277</td>\n",
       "      <td>0.644521</td>\n",
       "      <td>0.125635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.288365</td>\n",
       "      <td>0.137163</td>\n",
       "      <td>0.674518</td>\n",
       "      <td>0.282403</td>\n",
       "      <td>0.177454</td>\n",
       "      <td>0.478787</td>\n",
       "      <td>0.438882</td>\n",
       "      <td>0.478560</td>\n",
       "      <td>0.244772</td>\n",
       "      <td>0.277747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527941</td>\n",
       "      <td>0.621540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.298903</td>\n",
       "      <td>0.199036</td>\n",
       "      <td>0.437612</td>\n",
       "      <td>0.380958</td>\n",
       "      <td>0.480770</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.417238</td>\n",
       "      <td>0.490997</td>\n",
       "      <td>0.681220</td>\n",
       "      <td>0.474638</td>\n",
       "      <td>0.417165</td>\n",
       "      <td>0.363156</td>\n",
       "      <td>0.282075</td>\n",
       "      <td>0.835697</td>\n",
       "      <td>0.253787</td>\n",
       "      <td>0.652042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526235</td>\n",
       "      <td>0.461516</td>\n",
       "      <td>0.527927</td>\n",
       "      <td>0.297744</td>\n",
       "      <td>0.557738</td>\n",
       "      <td>0.165385</td>\n",
       "      <td>0.606437</td>\n",
       "      <td>0.559702</td>\n",
       "      <td>0.732312</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.433712</td>\n",
       "      <td>0.500565</td>\n",
       "      <td>0.590542</td>\n",
       "      <td>0.493207</td>\n",
       "      <td>0.526585</td>\n",
       "      <td>0.508253</td>\n",
       "      <td>0.619488</td>\n",
       "      <td>0.665435</td>\n",
       "      <td>0.522012</td>\n",
       "      <td>0.642790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348029</td>\n",
       "      <td>0.311587</td>\n",
       "      <td>0.449520</td>\n",
       "      <td>0.434645</td>\n",
       "      <td>0.554620</td>\n",
       "      <td>0.267342</td>\n",
       "      <td>0.334939</td>\n",
       "      <td>0.549557</td>\n",
       "      <td>0.696796</td>\n",
       "      <td>0.044648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.701910</td>\n",
       "      <td>0.271876</td>\n",
       "      <td>0.102990</td>\n",
       "      <td>0.427628</td>\n",
       "      <td>0.434947</td>\n",
       "      <td>0.108645</td>\n",
       "      <td>0.607485</td>\n",
       "      <td>0.597900</td>\n",
       "      <td>0.336430</td>\n",
       "      <td>0.592916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532471</td>\n",
       "      <td>0.505799</td>\n",
       "      <td>0.393950</td>\n",
       "      <td>0.319139</td>\n",
       "      <td>0.611830</td>\n",
       "      <td>0.347123</td>\n",
       "      <td>0.310281</td>\n",
       "      <td>0.638184</td>\n",
       "      <td>0.730074</td>\n",
       "      <td>0.030180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.1176082426487613       0.0  0.2269748071277395  0.2412416439712801  \\\n",
       "0              0.441943  0.572551            0.350845            0.442498   \n",
       "1              0.056807  0.178909            0.472918            0.448997   \n",
       "2              0.369264  0.499825            0.546073            0.686417   \n",
       "3              0.517284  0.455724            0.306775            0.467582   \n",
       "4              0.316393  0.249320            0.452914            0.342179   \n",
       "..                  ...       ...                 ...                 ...   \n",
       "147            0.529648  0.381934            0.229728            0.376578   \n",
       "148            0.288365  0.137163            0.674518            0.282403   \n",
       "149            0.417238  0.490997            0.681220            0.474638   \n",
       "150            0.433712  0.500565            0.590542            0.493207   \n",
       "151            0.701910  0.271876            0.102990            0.427628   \n",
       "\n",
       "     0.0912197106165378  0.5104254677127338     0.0.1  0.1521908825978353  \\\n",
       "0              0.455483            0.465932  0.567640            0.541632   \n",
       "1              0.293800            0.538865  0.373915            0.351504   \n",
       "2              0.430879            0.499019  0.360382            0.801572   \n",
       "3              0.338625            0.616611  0.516461            0.661558   \n",
       "4              0.333000            0.442517  0.372474            0.461386   \n",
       "..                  ...                 ...       ...                 ...   \n",
       "147            0.375803            0.329692  0.570968            0.603013   \n",
       "148            0.177454            0.478787  0.438882            0.478560   \n",
       "149            0.417165            0.363156  0.282075            0.835697   \n",
       "150            0.526585            0.508253  0.619488            0.665435   \n",
       "151            0.434947            0.108645  0.607485            0.597900   \n",
       "\n",
       "     0.1751909879580474  0.2727118952819632  ...  0.3183529411764706  \\\n",
       "0              0.303800            0.601140  ...            0.201412   \n",
       "1              0.125793            0.334049  ...            0.376324   \n",
       "2              0.259258            0.715122  ...            0.348206   \n",
       "3              0.350285            0.636688  ...            0.231471   \n",
       "4              0.411272            0.397715  ...            0.308941   \n",
       "..                  ...                 ...  ...                 ...   \n",
       "147            0.323449            0.644612  ...            0.378118   \n",
       "148            0.244772            0.277747  ...            0.527941   \n",
       "149            0.253787            0.652042  ...            0.526235   \n",
       "150            0.522012            0.642790  ...            0.348029   \n",
       "151            0.336430            0.592916  ...            0.532471   \n",
       "\n",
       "     0.3172808266118401  0.2419119458711597  0.1928461634331768  \\\n",
       "0              0.281275            0.283722            0.416615   \n",
       "1              0.472323            0.280007            0.107626   \n",
       "2              0.242185            0.399276            0.391744   \n",
       "3              0.293848            0.391866            0.271987   \n",
       "4              0.359850            0.174440            0.260189   \n",
       "..                  ...                 ...                 ...   \n",
       "147            0.373926            0.531717            0.401756   \n",
       "148            0.621540            0.000000            0.000000   \n",
       "149            0.461516            0.527927            0.297744   \n",
       "150            0.311587            0.449520            0.434645   \n",
       "151            0.505799            0.393950            0.319139   \n",
       "\n",
       "     0.4037368351474023  0.1411440702277813  0.4453436660649024  \\\n",
       "0              0.363879            0.446899            0.316261   \n",
       "1              0.140958            0.000000            0.405398   \n",
       "2              0.500991            0.000000            0.402924   \n",
       "3              0.495681            0.225773            0.346854   \n",
       "4              0.310856            0.126370            0.266021   \n",
       "..                  ...                 ...                 ...   \n",
       "147            0.523840            0.278214            0.292651   \n",
       "148            0.298903            0.199036            0.437612   \n",
       "149            0.557738            0.165385            0.606437   \n",
       "150            0.554620            0.267342            0.334939   \n",
       "151            0.611830            0.347123            0.310281   \n",
       "\n",
       "     0.2916373348792911  0.4124779561590263  0.2477462437395659  \n",
       "0              0.508924            0.511353            0.000000  \n",
       "1              0.256512            0.393719            0.000000  \n",
       "2              0.493613            0.676995            0.151771  \n",
       "3              0.600781            0.606043            0.036264  \n",
       "4              0.422026            0.489899            0.000000  \n",
       "..                  ...                 ...                 ...  \n",
       "147            0.601277            0.644521            0.125635  \n",
       "148            0.380958            0.480770            0.000000  \n",
       "149            0.559702            0.732312            0.000000  \n",
       "150            0.549557            0.696796            0.044648  \n",
       "151            0.638184            0.730074            0.030180  \n",
       "\n",
       "[152 rows x 49 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取制表符分隔的CSV文件\n",
    "miRNASeq_test = pd.read_csv('../../DATA/BRCA_survival/3_te.csv')\n",
    "# 显示 DataFrame\n",
    "miRNASeq_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1220144",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:37.171585Z",
     "iopub.status.busy": "2025-05-09T13:27:37.171157Z",
     "iopub.status.idle": "2025-05-09T13:27:37.173577Z",
     "shell.execute_reply": "2025-05-09T13:27:37.173113Z"
    },
    "papermill": {
     "duration": 0.008504,
     "end_time": "2025-05-09T13:27:37.174216",
     "exception": false,
     "start_time": "2025-05-09T13:27:37.165712",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 读取制表符分隔的CSV文件\n",
    "# miRNASeq_val = pd.read_csv('../../DATA/BRCA_survival/miRNASeq_val.csv')\n",
    "# # 显示 DataFrame\n",
    "# miRNASeq_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8d88d1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:37.185439Z",
     "iopub.status.busy": "2025-05-09T13:27:37.184976Z",
     "iopub.status.idle": "2025-05-09T13:27:37.251159Z",
     "shell.execute_reply": "2025-05-09T13:27:37.250677Z"
    },
    "papermill": {
     "duration": 0.072619,
     "end_time": "2025-05-09T13:27:37.251885",
     "exception": false,
     "start_time": "2025-05-09T13:27:37.179266",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.5608555785167986</th>\n",
       "      <th>0.1766963352671975</th>\n",
       "      <th>0.6809032567128923</th>\n",
       "      <th>0.4107881498043606</th>\n",
       "      <th>0.7015425270403147</th>\n",
       "      <th>0.2326074935361899</th>\n",
       "      <th>0.2890965268212788</th>\n",
       "      <th>0.7044968743698328</th>\n",
       "      <th>0.4316677429770745</th>\n",
       "      <th>0.27732987883868</th>\n",
       "      <th>...</th>\n",
       "      <th>0.4884248988646744</th>\n",
       "      <th>0.38787170497338</th>\n",
       "      <th>0.7090433094856572</th>\n",
       "      <th>0.2148936170212763</th>\n",
       "      <th>0.3616304689959078</th>\n",
       "      <th>0.0.21</th>\n",
       "      <th>0.3116487698790267</th>\n",
       "      <th>0.4638785035877668</th>\n",
       "      <th>0.4313665799523991</th>\n",
       "      <th>0.2154454446033482</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.604593</td>\n",
       "      <td>0.637959</td>\n",
       "      <td>0.576380</td>\n",
       "      <td>0.556037</td>\n",
       "      <td>0.587082</td>\n",
       "      <td>0.309994</td>\n",
       "      <td>0.495105</td>\n",
       "      <td>0.562674</td>\n",
       "      <td>0.473200</td>\n",
       "      <td>0.381833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297612</td>\n",
       "      <td>0.527347</td>\n",
       "      <td>0.665463</td>\n",
       "      <td>0.589118</td>\n",
       "      <td>0.408971</td>\n",
       "      <td>0.368389</td>\n",
       "      <td>0.403860</td>\n",
       "      <td>0.473307</td>\n",
       "      <td>0.492971</td>\n",
       "      <td>0.233771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.539083</td>\n",
       "      <td>0.618455</td>\n",
       "      <td>0.657149</td>\n",
       "      <td>0.412409</td>\n",
       "      <td>0.595793</td>\n",
       "      <td>0.387709</td>\n",
       "      <td>0.731452</td>\n",
       "      <td>0.490058</td>\n",
       "      <td>0.442969</td>\n",
       "      <td>0.430115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421793</td>\n",
       "      <td>0.440878</td>\n",
       "      <td>0.538040</td>\n",
       "      <td>0.485455</td>\n",
       "      <td>0.613818</td>\n",
       "      <td>0.468062</td>\n",
       "      <td>0.462281</td>\n",
       "      <td>0.537074</td>\n",
       "      <td>0.567139</td>\n",
       "      <td>0.315176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.496261</td>\n",
       "      <td>0.364221</td>\n",
       "      <td>0.572076</td>\n",
       "      <td>0.034628</td>\n",
       "      <td>0.327480</td>\n",
       "      <td>0.157582</td>\n",
       "      <td>0.466553</td>\n",
       "      <td>0.712079</td>\n",
       "      <td>0.579371</td>\n",
       "      <td>0.137149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355005</td>\n",
       "      <td>0.200961</td>\n",
       "      <td>0.931007</td>\n",
       "      <td>0.517893</td>\n",
       "      <td>0.166950</td>\n",
       "      <td>0.043348</td>\n",
       "      <td>0.408264</td>\n",
       "      <td>0.127000</td>\n",
       "      <td>0.258455</td>\n",
       "      <td>0.187488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.520356</td>\n",
       "      <td>0.413814</td>\n",
       "      <td>0.456477</td>\n",
       "      <td>0.515484</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>0.371314</td>\n",
       "      <td>0.432602</td>\n",
       "      <td>0.516757</td>\n",
       "      <td>0.318231</td>\n",
       "      <td>0.420681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447919</td>\n",
       "      <td>0.498675</td>\n",
       "      <td>0.422939</td>\n",
       "      <td>0.540426</td>\n",
       "      <td>0.533617</td>\n",
       "      <td>0.123905</td>\n",
       "      <td>0.673726</td>\n",
       "      <td>0.541463</td>\n",
       "      <td>0.493690</td>\n",
       "      <td>0.285887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.503568</td>\n",
       "      <td>0.641112</td>\n",
       "      <td>0.720854</td>\n",
       "      <td>0.369704</td>\n",
       "      <td>0.622573</td>\n",
       "      <td>0.345743</td>\n",
       "      <td>0.516175</td>\n",
       "      <td>0.480762</td>\n",
       "      <td>0.387250</td>\n",
       "      <td>0.479982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474566</td>\n",
       "      <td>0.659278</td>\n",
       "      <td>0.509738</td>\n",
       "      <td>0.446983</td>\n",
       "      <td>0.628140</td>\n",
       "      <td>0.429199</td>\n",
       "      <td>0.419057</td>\n",
       "      <td>0.594408</td>\n",
       "      <td>0.548459</td>\n",
       "      <td>0.295519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0.518290</td>\n",
       "      <td>0.473217</td>\n",
       "      <td>0.599275</td>\n",
       "      <td>0.311710</td>\n",
       "      <td>0.711283</td>\n",
       "      <td>0.303478</td>\n",
       "      <td>0.551018</td>\n",
       "      <td>0.507965</td>\n",
       "      <td>0.461858</td>\n",
       "      <td>0.307171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407230</td>\n",
       "      <td>0.248215</td>\n",
       "      <td>0.594732</td>\n",
       "      <td>0.498500</td>\n",
       "      <td>0.514857</td>\n",
       "      <td>0.601895</td>\n",
       "      <td>0.493870</td>\n",
       "      <td>0.649444</td>\n",
       "      <td>0.369486</td>\n",
       "      <td>0.223283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>0.522572</td>\n",
       "      <td>0.518576</td>\n",
       "      <td>0.670942</td>\n",
       "      <td>0.491336</td>\n",
       "      <td>0.544386</td>\n",
       "      <td>0.373661</td>\n",
       "      <td>0.500875</td>\n",
       "      <td>0.567977</td>\n",
       "      <td>0.410559</td>\n",
       "      <td>0.371348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369594</td>\n",
       "      <td>0.646799</td>\n",
       "      <td>0.507798</td>\n",
       "      <td>0.361039</td>\n",
       "      <td>0.585143</td>\n",
       "      <td>0.645461</td>\n",
       "      <td>0.290580</td>\n",
       "      <td>0.648794</td>\n",
       "      <td>0.492860</td>\n",
       "      <td>0.192213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>0.291229</td>\n",
       "      <td>0.204542</td>\n",
       "      <td>0.584862</td>\n",
       "      <td>0.728032</td>\n",
       "      <td>0.665038</td>\n",
       "      <td>0.418048</td>\n",
       "      <td>0.692365</td>\n",
       "      <td>0.365053</td>\n",
       "      <td>0.610510</td>\n",
       "      <td>0.345424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497534</td>\n",
       "      <td>0.695027</td>\n",
       "      <td>0.185741</td>\n",
       "      <td>0.476352</td>\n",
       "      <td>0.736701</td>\n",
       "      <td>0.207578</td>\n",
       "      <td>0.664320</td>\n",
       "      <td>0.692567</td>\n",
       "      <td>0.776914</td>\n",
       "      <td>0.299501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>0.622127</td>\n",
       "      <td>0.697371</td>\n",
       "      <td>0.557622</td>\n",
       "      <td>0.552068</td>\n",
       "      <td>0.753733</td>\n",
       "      <td>0.450868</td>\n",
       "      <td>0.765663</td>\n",
       "      <td>0.269570</td>\n",
       "      <td>0.394616</td>\n",
       "      <td>0.452412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398408</td>\n",
       "      <td>0.476639</td>\n",
       "      <td>0.345212</td>\n",
       "      <td>0.496338</td>\n",
       "      <td>0.753824</td>\n",
       "      <td>0.665729</td>\n",
       "      <td>0.270110</td>\n",
       "      <td>0.510903</td>\n",
       "      <td>0.706592</td>\n",
       "      <td>0.316256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>0.474914</td>\n",
       "      <td>0.402112</td>\n",
       "      <td>0.487334</td>\n",
       "      <td>0.544634</td>\n",
       "      <td>0.613462</td>\n",
       "      <td>0.325821</td>\n",
       "      <td>0.397871</td>\n",
       "      <td>0.588022</td>\n",
       "      <td>0.485026</td>\n",
       "      <td>0.416383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.490174</td>\n",
       "      <td>0.402039</td>\n",
       "      <td>0.534835</td>\n",
       "      <td>0.494070</td>\n",
       "      <td>0.368901</td>\n",
       "      <td>0.486297</td>\n",
       "      <td>0.570151</td>\n",
       "      <td>0.606391</td>\n",
       "      <td>0.497011</td>\n",
       "      <td>0.274950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458 rows × 738 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.5608555785167986  0.1766963352671975  0.6809032567128923  \\\n",
       "0              0.604593            0.637959            0.576380   \n",
       "1              0.539083            0.618455            0.657149   \n",
       "2              0.496261            0.364221            0.572076   \n",
       "3              0.520356            0.413814            0.456477   \n",
       "4              0.503568            0.641112            0.720854   \n",
       "..                  ...                 ...                 ...   \n",
       "453            0.518290            0.473217            0.599275   \n",
       "454            0.522572            0.518576            0.670942   \n",
       "455            0.291229            0.204542            0.584862   \n",
       "456            0.622127            0.697371            0.557622   \n",
       "457            0.474914            0.402112            0.487334   \n",
       "\n",
       "     0.4107881498043606  0.7015425270403147  0.2326074935361899  \\\n",
       "0              0.556037            0.587082            0.309994   \n",
       "1              0.412409            0.595793            0.387709   \n",
       "2              0.034628            0.327480            0.157582   \n",
       "3              0.515484            0.761538            0.371314   \n",
       "4              0.369704            0.622573            0.345743   \n",
       "..                  ...                 ...                 ...   \n",
       "453            0.311710            0.711283            0.303478   \n",
       "454            0.491336            0.544386            0.373661   \n",
       "455            0.728032            0.665038            0.418048   \n",
       "456            0.552068            0.753733            0.450868   \n",
       "457            0.544634            0.613462            0.325821   \n",
       "\n",
       "     0.2890965268212788  0.7044968743698328  0.4316677429770745  \\\n",
       "0              0.495105            0.562674            0.473200   \n",
       "1              0.731452            0.490058            0.442969   \n",
       "2              0.466553            0.712079            0.579371   \n",
       "3              0.432602            0.516757            0.318231   \n",
       "4              0.516175            0.480762            0.387250   \n",
       "..                  ...                 ...                 ...   \n",
       "453            0.551018            0.507965            0.461858   \n",
       "454            0.500875            0.567977            0.410559   \n",
       "455            0.692365            0.365053            0.610510   \n",
       "456            0.765663            0.269570            0.394616   \n",
       "457            0.397871            0.588022            0.485026   \n",
       "\n",
       "     0.27732987883868  ...  0.4884248988646744  0.38787170497338  \\\n",
       "0            0.381833  ...            0.297612          0.527347   \n",
       "1            0.430115  ...            0.421793          0.440878   \n",
       "2            0.137149  ...            0.355005          0.200961   \n",
       "3            0.420681  ...            0.447919          0.498675   \n",
       "4            0.479982  ...            0.474566          0.659278   \n",
       "..                ...  ...                 ...               ...   \n",
       "453          0.307171  ...            0.407230          0.248215   \n",
       "454          0.371348  ...            0.369594          0.646799   \n",
       "455          0.345424  ...            0.497534          0.695027   \n",
       "456          0.452412  ...            0.398408          0.476639   \n",
       "457          0.416383  ...            0.490174          0.402039   \n",
       "\n",
       "     0.7090433094856572  0.2148936170212763  0.3616304689959078    0.0.21  \\\n",
       "0              0.665463            0.589118            0.408971  0.368389   \n",
       "1              0.538040            0.485455            0.613818  0.468062   \n",
       "2              0.931007            0.517893            0.166950  0.043348   \n",
       "3              0.422939            0.540426            0.533617  0.123905   \n",
       "4              0.509738            0.446983            0.628140  0.429199   \n",
       "..                  ...                 ...                 ...       ...   \n",
       "453            0.594732            0.498500            0.514857  0.601895   \n",
       "454            0.507798            0.361039            0.585143  0.645461   \n",
       "455            0.185741            0.476352            0.736701  0.207578   \n",
       "456            0.345212            0.496338            0.753824  0.665729   \n",
       "457            0.534835            0.494070            0.368901  0.486297   \n",
       "\n",
       "     0.3116487698790267  0.4638785035877668  0.4313665799523991  \\\n",
       "0              0.403860            0.473307            0.492971   \n",
       "1              0.462281            0.537074            0.567139   \n",
       "2              0.408264            0.127000            0.258455   \n",
       "3              0.673726            0.541463            0.493690   \n",
       "4              0.419057            0.594408            0.548459   \n",
       "..                  ...                 ...                 ...   \n",
       "453            0.493870            0.649444            0.369486   \n",
       "454            0.290580            0.648794            0.492860   \n",
       "455            0.664320            0.692567            0.776914   \n",
       "456            0.270110            0.510903            0.706592   \n",
       "457            0.570151            0.606391            0.497011   \n",
       "\n",
       "     0.2154454446033482  \n",
       "0              0.233771  \n",
       "1              0.315176  \n",
       "2              0.187488  \n",
       "3              0.285887  \n",
       "4              0.295519  \n",
       "..                  ...  \n",
       "453            0.223283  \n",
       "454            0.192213  \n",
       "455            0.299501  \n",
       "456            0.316256  \n",
       "457            0.274950  \n",
       "\n",
       "[458 rows x 738 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取制表符分隔的CSV文件\n",
    "RNAseq_train = pd.read_csv('../../DATA/BRCA_survival/2_tr.csv')\n",
    "# 显示 DataFrame\n",
    "RNAseq_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff830335",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:37.267064Z",
     "iopub.status.busy": "2025-05-09T13:27:37.266789Z",
     "iopub.status.idle": "2025-05-09T13:27:37.305109Z",
     "shell.execute_reply": "2025-05-09T13:27:37.304605Z"
    },
    "papermill": {
     "duration": 0.048271,
     "end_time": "2025-05-09T13:27:37.305845",
     "exception": false,
     "start_time": "2025-05-09T13:27:37.257574",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.8306099405611542</th>\n",
       "      <th>0.1649400021620842</th>\n",
       "      <th>0.8170112246330727</th>\n",
       "      <th>0.0158188932364446</th>\n",
       "      <th>0.6762844149459194</th>\n",
       "      <th>0.5039829026617448</th>\n",
       "      <th>0.5283103153035773</th>\n",
       "      <th>0.5772333131679779</th>\n",
       "      <th>0.4171577332902809</th>\n",
       "      <th>0.3703726282100128</th>\n",
       "      <th>...</th>\n",
       "      <th>0.4583844447344383</th>\n",
       "      <th>0.4175172055577197</th>\n",
       "      <th>0.7479518833645533</th>\n",
       "      <th>0.4747471224276247</th>\n",
       "      <th>0.4240163676424298</th>\n",
       "      <th>0.153780898546099</th>\n",
       "      <th>0.5342938697838793</th>\n",
       "      <th>0.4278382834451846</th>\n",
       "      <th>0.36677367576244</th>\n",
       "      <th>0.2980146378396566</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.461578</td>\n",
       "      <td>0.390022</td>\n",
       "      <td>0.469320</td>\n",
       "      <td>0.591140</td>\n",
       "      <td>0.707473</td>\n",
       "      <td>0.352722</td>\n",
       "      <td>0.755612</td>\n",
       "      <td>0.524844</td>\n",
       "      <td>0.421154</td>\n",
       "      <td>0.401219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389847</td>\n",
       "      <td>0.345059</td>\n",
       "      <td>0.452955</td>\n",
       "      <td>0.573736</td>\n",
       "      <td>0.533805</td>\n",
       "      <td>0.299045</td>\n",
       "      <td>0.600979</td>\n",
       "      <td>0.408262</td>\n",
       "      <td>0.555239</td>\n",
       "      <td>0.286896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.403183</td>\n",
       "      <td>0.205425</td>\n",
       "      <td>0.400519</td>\n",
       "      <td>0.579989</td>\n",
       "      <td>0.652809</td>\n",
       "      <td>0.422277</td>\n",
       "      <td>0.430890</td>\n",
       "      <td>0.368744</td>\n",
       "      <td>0.516387</td>\n",
       "      <td>0.471158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513089</td>\n",
       "      <td>0.528126</td>\n",
       "      <td>0.512040</td>\n",
       "      <td>0.721904</td>\n",
       "      <td>0.487252</td>\n",
       "      <td>0.300473</td>\n",
       "      <td>0.576893</td>\n",
       "      <td>0.608364</td>\n",
       "      <td>0.611751</td>\n",
       "      <td>0.289195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.515264</td>\n",
       "      <td>0.445074</td>\n",
       "      <td>0.724563</td>\n",
       "      <td>0.510397</td>\n",
       "      <td>0.709731</td>\n",
       "      <td>0.568128</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.343154</td>\n",
       "      <td>0.295528</td>\n",
       "      <td>0.507247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.604019</td>\n",
       "      <td>0.616258</td>\n",
       "      <td>0.262565</td>\n",
       "      <td>0.441786</td>\n",
       "      <td>0.550677</td>\n",
       "      <td>0.168521</td>\n",
       "      <td>0.396493</td>\n",
       "      <td>0.612637</td>\n",
       "      <td>0.570737</td>\n",
       "      <td>0.358305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.589105</td>\n",
       "      <td>0.613924</td>\n",
       "      <td>0.777077</td>\n",
       "      <td>0.489296</td>\n",
       "      <td>0.656865</td>\n",
       "      <td>0.420006</td>\n",
       "      <td>0.601124</td>\n",
       "      <td>0.515104</td>\n",
       "      <td>0.437258</td>\n",
       "      <td>0.501715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262247</td>\n",
       "      <td>0.518803</td>\n",
       "      <td>0.472184</td>\n",
       "      <td>0.398430</td>\n",
       "      <td>0.562764</td>\n",
       "      <td>0.498316</td>\n",
       "      <td>0.493870</td>\n",
       "      <td>0.501126</td>\n",
       "      <td>0.419992</td>\n",
       "      <td>0.347943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.532777</td>\n",
       "      <td>0.115951</td>\n",
       "      <td>0.342066</td>\n",
       "      <td>0.969285</td>\n",
       "      <td>0.544386</td>\n",
       "      <td>0.221862</td>\n",
       "      <td>0.429736</td>\n",
       "      <td>0.645191</td>\n",
       "      <td>0.365172</td>\n",
       "      <td>0.293241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483727</td>\n",
       "      <td>0.306636</td>\n",
       "      <td>0.616918</td>\n",
       "      <td>0.458982</td>\n",
       "      <td>0.331634</td>\n",
       "      <td>0.129868</td>\n",
       "      <td>0.382058</td>\n",
       "      <td>0.594989</td>\n",
       "      <td>0.524520</td>\n",
       "      <td>0.199938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.595688</td>\n",
       "      <td>0.604086</td>\n",
       "      <td>0.641473</td>\n",
       "      <td>0.489575</td>\n",
       "      <td>0.629932</td>\n",
       "      <td>0.314433</td>\n",
       "      <td>0.553773</td>\n",
       "      <td>0.605182</td>\n",
       "      <td>0.445128</td>\n",
       "      <td>0.404511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332376</td>\n",
       "      <td>0.467848</td>\n",
       "      <td>0.583945</td>\n",
       "      <td>0.417824</td>\n",
       "      <td>0.550268</td>\n",
       "      <td>0.461040</td>\n",
       "      <td>0.458910</td>\n",
       "      <td>0.526438</td>\n",
       "      <td>0.552527</td>\n",
       "      <td>0.267155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.584567</td>\n",
       "      <td>0.383734</td>\n",
       "      <td>0.501854</td>\n",
       "      <td>0.509419</td>\n",
       "      <td>0.698516</td>\n",
       "      <td>0.405195</td>\n",
       "      <td>0.583516</td>\n",
       "      <td>0.763682</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.576743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.479421</td>\n",
       "      <td>0.521621</td>\n",
       "      <td>0.396827</td>\n",
       "      <td>0.495256</td>\n",
       "      <td>0.567391</td>\n",
       "      <td>0.287017</td>\n",
       "      <td>0.489248</td>\n",
       "      <td>0.476325</td>\n",
       "      <td>0.679969</td>\n",
       "      <td>0.307002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.118026</td>\n",
       "      <td>0.269351</td>\n",
       "      <td>0.454222</td>\n",
       "      <td>0.312186</td>\n",
       "      <td>0.647262</td>\n",
       "      <td>0.470805</td>\n",
       "      <td>0.716264</td>\n",
       "      <td>0.227889</td>\n",
       "      <td>0.246489</td>\n",
       "      <td>0.508116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823829</td>\n",
       "      <td>0.684275</td>\n",
       "      <td>0.253786</td>\n",
       "      <td>0.386118</td>\n",
       "      <td>0.455807</td>\n",
       "      <td>0.093172</td>\n",
       "      <td>0.484600</td>\n",
       "      <td>0.877877</td>\n",
       "      <td>0.933498</td>\n",
       "      <td>0.366913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.480198</td>\n",
       "      <td>0.571223</td>\n",
       "      <td>0.638012</td>\n",
       "      <td>0.438010</td>\n",
       "      <td>0.527532</td>\n",
       "      <td>0.345922</td>\n",
       "      <td>0.381082</td>\n",
       "      <td>0.551482</td>\n",
       "      <td>0.451889</td>\n",
       "      <td>0.368391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286989</td>\n",
       "      <td>0.416530</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.440426</td>\n",
       "      <td>0.512307</td>\n",
       "      <td>0.304001</td>\n",
       "      <td>0.276172</td>\n",
       "      <td>0.412674</td>\n",
       "      <td>0.351968</td>\n",
       "      <td>0.210160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.419374</td>\n",
       "      <td>0.594879</td>\n",
       "      <td>0.632527</td>\n",
       "      <td>0.578060</td>\n",
       "      <td>0.682937</td>\n",
       "      <td>0.444755</td>\n",
       "      <td>0.530842</td>\n",
       "      <td>0.364469</td>\n",
       "      <td>0.306022</td>\n",
       "      <td>0.496441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498760</td>\n",
       "      <td>0.693326</td>\n",
       "      <td>0.358753</td>\n",
       "      <td>0.473875</td>\n",
       "      <td>0.615423</td>\n",
       "      <td>0.355513</td>\n",
       "      <td>0.610765</td>\n",
       "      <td>0.750923</td>\n",
       "      <td>0.573283</td>\n",
       "      <td>0.360057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 738 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.8306099405611542  0.1649400021620842  0.8170112246330727  \\\n",
       "0              0.461578            0.390022            0.469320   \n",
       "1              0.403183            0.205425            0.400519   \n",
       "2              0.515264            0.445074            0.724563   \n",
       "3              0.589105            0.613924            0.777077   \n",
       "4              0.532777            0.115951            0.342066   \n",
       "..                  ...                 ...                 ...   \n",
       "147            0.595688            0.604086            0.641473   \n",
       "148            0.584567            0.383734            0.501854   \n",
       "149            0.118026            0.269351            0.454222   \n",
       "150            0.480198            0.571223            0.638012   \n",
       "151            0.419374            0.594879            0.632527   \n",
       "\n",
       "     0.0158188932364446  0.6762844149459194  0.5039829026617448  \\\n",
       "0              0.591140            0.707473            0.352722   \n",
       "1              0.579989            0.652809            0.422277   \n",
       "2              0.510397            0.709731            0.568128   \n",
       "3              0.489296            0.656865            0.420006   \n",
       "4              0.969285            0.544386            0.221862   \n",
       "..                  ...                 ...                 ...   \n",
       "147            0.489575            0.629932            0.314433   \n",
       "148            0.509419            0.698516            0.405195   \n",
       "149            0.312186            0.647262            0.470805   \n",
       "150            0.438010            0.527532            0.345922   \n",
       "151            0.578060            0.682937            0.444755   \n",
       "\n",
       "     0.5283103153035773  0.5772333131679779  0.4171577332902809  \\\n",
       "0              0.755612            0.524844            0.421154   \n",
       "1              0.430890            0.368744            0.516387   \n",
       "2              0.645833            0.343154            0.295528   \n",
       "3              0.601124            0.515104            0.437258   \n",
       "4              0.429736            0.645191            0.365172   \n",
       "..                  ...                 ...                 ...   \n",
       "147            0.553773            0.605182            0.445128   \n",
       "148            0.583516            0.763682            1.000000   \n",
       "149            0.716264            0.227889            0.246489   \n",
       "150            0.381082            0.551482            0.451889   \n",
       "151            0.530842            0.364469            0.306022   \n",
       "\n",
       "     0.3703726282100128  ...  0.4583844447344383  0.4175172055577197  \\\n",
       "0              0.401219  ...            0.389847            0.345059   \n",
       "1              0.471158  ...            0.513089            0.528126   \n",
       "2              0.507247  ...            0.604019            0.616258   \n",
       "3              0.501715  ...            0.262247            0.518803   \n",
       "4              0.293241  ...            0.483727            0.306636   \n",
       "..                  ...  ...                 ...                 ...   \n",
       "147            0.404511  ...            0.332376            0.467848   \n",
       "148            0.576743  ...            0.479421            0.521621   \n",
       "149            0.508116  ...            0.823829            0.684275   \n",
       "150            0.368391  ...            0.286989            0.416530   \n",
       "151            0.496441  ...            0.498760            0.693326   \n",
       "\n",
       "     0.7479518833645533  0.4747471224276247  0.4240163676424298  \\\n",
       "0              0.452955            0.573736            0.533805   \n",
       "1              0.512040            0.721904            0.487252   \n",
       "2              0.262565            0.441786            0.550677   \n",
       "3              0.472184            0.398430            0.562764   \n",
       "4              0.616918            0.458982            0.331634   \n",
       "..                  ...                 ...                 ...   \n",
       "147            0.583945            0.417824            0.550268   \n",
       "148            0.396827            0.495256            0.567391   \n",
       "149            0.253786            0.386118            0.455807   \n",
       "150            0.818750            0.440426            0.512307   \n",
       "151            0.358753            0.473875            0.615423   \n",
       "\n",
       "     0.153780898546099  0.5342938697838793  0.4278382834451846  \\\n",
       "0             0.299045            0.600979            0.408262   \n",
       "1             0.300473            0.576893            0.608364   \n",
       "2             0.168521            0.396493            0.612637   \n",
       "3             0.498316            0.493870            0.501126   \n",
       "4             0.129868            0.382058            0.594989   \n",
       "..                 ...                 ...                 ...   \n",
       "147           0.461040            0.458910            0.526438   \n",
       "148           0.287017            0.489248            0.476325   \n",
       "149           0.093172            0.484600            0.877877   \n",
       "150           0.304001            0.276172            0.412674   \n",
       "151           0.355513            0.610765            0.750923   \n",
       "\n",
       "     0.36677367576244  0.2980146378396566  \n",
       "0            0.555239            0.286896  \n",
       "1            0.611751            0.289195  \n",
       "2            0.570737            0.358305  \n",
       "3            0.419992            0.347943  \n",
       "4            0.524520            0.199938  \n",
       "..                ...                 ...  \n",
       "147          0.552527            0.267155  \n",
       "148          0.679969            0.307002  \n",
       "149          0.933498            0.366913  \n",
       "150          0.351968            0.210160  \n",
       "151          0.573283            0.360057  \n",
       "\n",
       "[152 rows x 738 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取制表符分隔的CSV文件\n",
    "RNAseq_test = pd.read_csv('../../DATA/BRCA_survival/2_te.csv')\n",
    "# 显示 DataFrame\n",
    "RNAseq_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bcf918a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:37.329579Z",
     "iopub.status.busy": "2025-05-09T13:27:37.329190Z",
     "iopub.status.idle": "2025-05-09T13:27:37.331561Z",
     "shell.execute_reply": "2025-05-09T13:27:37.331115Z"
    },
    "papermill": {
     "duration": 0.020311,
     "end_time": "2025-05-09T13:27:37.332245",
     "exception": false,
     "start_time": "2025-05-09T13:27:37.311934",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 读取制表符分隔的CSV文件\n",
    "# RNAseq_val = pd.read_csv('../../DATA/BRCA_survival/RNAseq_val.csv')\n",
    "# # 显示 DataFrame\n",
    "# RNAseq_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fb4c79b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:37.364723Z",
     "iopub.status.busy": "2025-05-09T13:27:37.364202Z",
     "iopub.status.idle": "2025-05-09T13:27:37.370984Z",
     "shell.execute_reply": "2025-05-09T13:27:37.370523Z"
    },
    "papermill": {
     "duration": 0.026171,
     "end_time": "2025-05-09T13:27:37.371728",
     "exception": false,
     "start_time": "2025-05-09T13:27:37.345557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "0    315\n",
       "1    143\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用np.load()函数加载.npy文件\n",
    "labels_train = pd.read_csv('../../DATA/BRCA_survival/labels_tr.csv')\n",
    "labels_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36706f05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:37.397858Z",
     "iopub.status.busy": "2025-05-09T13:27:37.397466Z",
     "iopub.status.idle": "2025-05-09T13:27:37.403784Z",
     "shell.execute_reply": "2025-05-09T13:27:37.403308Z"
    },
    "papermill": {
     "duration": 0.016864,
     "end_time": "2025-05-09T13:27:37.404545",
     "exception": false,
     "start_time": "2025-05-09T13:27:37.387681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "0    107\n",
       "1     45\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用np.load()函数加载.npy文件\n",
    "labels_test = pd.read_csv('../../DATA/BRCA_survival/labels_te.csv')\n",
    "labels_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e068632b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:37.431975Z",
     "iopub.status.busy": "2025-05-09T13:27:37.431533Z",
     "iopub.status.idle": "2025-05-09T13:27:37.433954Z",
     "shell.execute_reply": "2025-05-09T13:27:37.433519Z"
    },
    "papermill": {
     "duration": 0.02003,
     "end_time": "2025-05-09T13:27:37.434632",
     "exception": false,
     "start_time": "2025-05-09T13:27:37.414602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 使用np.load()函数加载.npy文件\n",
    "# labels_val = pd.read_csv('../../DATA/BRCA_survival/labels_val.csv')\n",
    "# labels_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "813d1549",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:37.450815Z",
     "iopub.status.busy": "2025-05-09T13:27:37.450418Z",
     "iopub.status.idle": "2025-05-09T13:27:37.454335Z",
     "shell.execute_reply": "2025-05-09T13:27:37.453834Z"
    },
    "papermill": {
     "duration": 0.011473,
     "end_time": "2025-05-09T13:27:37.455143",
     "exception": false,
     "start_time": "2025-05-09T13:27:37.443670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dim = len(np.unique(labels_train))\n",
    "label_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aae8d01b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:37.478693Z",
     "iopub.status.busy": "2025-05-09T13:27:37.478293Z",
     "iopub.status.idle": "2025-05-09T13:27:37.570375Z",
     "shell.execute_reply": "2025-05-09T13:27:37.569674Z"
    },
    "papermill": {
     "duration": 0.110027,
     "end_time": "2025-05-09T13:27:37.571538",
     "exception": false,
     "start_time": "2025-05-09T13:27:37.461511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 使用 GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a28be32d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:37.600762Z",
     "iopub.status.busy": "2025-05-09T13:27:37.600369Z",
     "iopub.status.idle": "2025-05-09T13:27:38.001023Z",
     "shell.execute_reply": "2025-05-09T13:27:38.000174Z"
    },
    "papermill": {
     "duration": 0.41967,
     "end_time": "2025-05-09T13:27:38.002115",
     "exception": false,
     "start_time": "2025-05-09T13:27:37.582445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 0 已转换为 Tensor，并移动到 cuda:0\n",
      "DataFrame 1 已转换为 Tensor，并移动到 cuda:0\n",
      "DataFrame 2 已转换为 Tensor，并移动到 cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 调用函数，将这些 numpy 数组转换为 tensors\n",
    "train_tensors = batch_dataframe_to_tensors(Methylation_train, miRNASeq_train, RNAseq_train)\n",
    "\n",
    "# 现在 tensors 是一个包含这些转换后张量的列表\n",
    "Methylation_train = train_tensors[0]\n",
    "miRNASeq_train = train_tensors[1]\n",
    "RNAseq_train = train_tensors[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a23632e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:38.027303Z",
     "iopub.status.busy": "2025-05-09T13:27:38.027058Z",
     "iopub.status.idle": "2025-05-09T13:27:38.040912Z",
     "shell.execute_reply": "2025-05-09T13:27:38.040228Z"
    },
    "papermill": {
     "duration": 0.028988,
     "end_time": "2025-05-09T13:27:38.041800",
     "exception": false,
     "start_time": "2025-05-09T13:27:38.012812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 0 已转换为 Tensor，并移动到 cuda:0\n",
      "DataFrame 1 已转换为 Tensor，并移动到 cuda:0\n",
      "DataFrame 2 已转换为 Tensor，并移动到 cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 调用函数，将这些 numpy 数组转换为 tensors\n",
    "test_tensors = batch_dataframe_to_tensors(Methylation_test, miRNASeq_test, RNAseq_test)\n",
    "\n",
    "# 现在 tensors 是一个包含这些转换后张量的列表\n",
    "Methylation_test = test_tensors[0]\n",
    "miRNASeq_test = test_tensors[1]\n",
    "RNAseq_test = test_tensors[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03468a79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:38.068466Z",
     "iopub.status.busy": "2025-05-09T13:27:38.068266Z",
     "iopub.status.idle": "2025-05-09T13:27:38.071127Z",
     "shell.execute_reply": "2025-05-09T13:27:38.070569Z"
    },
    "papermill": {
     "duration": 0.020574,
     "end_time": "2025-05-09T13:27:38.071940",
     "exception": false,
     "start_time": "2025-05-09T13:27:38.051366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 调用函数，将这些 numpy 数组转换为 tensors\n",
    "# val_tensors = batch_dataframe_to_tensors(Methylation_val, miRNASeq_val, RNAseq_val)\n",
    "\n",
    "# # 现在 tensors 是一个包含这些转换后张量的列表\n",
    "# Methylation_val = val_tensors[0]\n",
    "# miRNASeq_val = val_tensors[1]\n",
    "# RNAseq_val = val_tensors[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8860b5d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:38.112266Z",
     "iopub.status.busy": "2025-05-09T13:27:38.112019Z",
     "iopub.status.idle": "2025-05-09T13:27:38.123641Z",
     "shell.execute_reply": "2025-05-09T13:27:38.123217Z"
    },
    "papermill": {
     "duration": 0.025261,
     "end_time": "2025-05-09T13:27:38.124580",
     "exception": false,
     "start_time": "2025-05-09T13:27:38.099319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将DataFrame的值转换为Tensor\n",
    "labels_tr_tensor = torch.LongTensor(labels_train.values)\n",
    "labels_tr_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e593db4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:38.152712Z",
     "iopub.status.busy": "2025-05-09T13:27:38.152512Z",
     "iopub.status.idle": "2025-05-09T13:27:38.155478Z",
     "shell.execute_reply": "2025-05-09T13:27:38.155066Z"
    },
    "papermill": {
     "duration": 0.022075,
     "end_time": "2025-05-09T13:27:38.156341",
     "exception": false,
     "start_time": "2025-05-09T13:27:38.134266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "onehot_labels_tr_tensor = one_hot_tensor(labels_tr_tensor, num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0203bbc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:38.185417Z",
     "iopub.status.busy": "2025-05-09T13:27:38.185215Z",
     "iopub.status.idle": "2025-05-09T13:27:38.191140Z",
     "shell.execute_reply": "2025-05-09T13:27:38.190740Z"
    },
    "papermill": {
     "duration": 0.022695,
     "end_time": "2025-05-09T13:27:38.197650",
     "exception": false,
     "start_time": "2025-05-09T13:27:38.174955",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将DataFrame的值转换为Tensor\n",
    "labels_te_tensor = torch.LongTensor(labels_test.values)\n",
    "labels_te_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0b725ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:38.226930Z",
     "iopub.status.busy": "2025-05-09T13:27:38.226659Z",
     "iopub.status.idle": "2025-05-09T13:27:38.236948Z",
     "shell.execute_reply": "2025-05-09T13:27:38.236469Z"
    },
    "papermill": {
     "duration": 0.022312,
     "end_time": "2025-05-09T13:27:38.237736",
     "exception": false,
     "start_time": "2025-05-09T13:27:38.215424",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将DataFrame的值转换为Tensor\n",
    "labels_tr_tensor = torch.LongTensor(labels_train.values)\n",
    "labels_tr_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9b7910e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:38.252832Z",
     "iopub.status.busy": "2025-05-09T13:27:38.252564Z",
     "iopub.status.idle": "2025-05-09T13:27:38.254974Z",
     "shell.execute_reply": "2025-05-09T13:27:38.254567Z"
    },
    "papermill": {
     "duration": 0.010911,
     "end_time": "2025-05-09T13:27:38.255790",
     "exception": false,
     "start_time": "2025-05-09T13:27:38.244879",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 将DataFrame的值转换为Tensor\n",
    "# labels_val_tensor = torch.LongTensor(labels_val.values)\n",
    "# labels_val_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a22e9c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:38.281541Z",
     "iopub.status.busy": "2025-05-09T13:27:38.281297Z",
     "iopub.status.idle": "2025-05-09T13:27:38.286366Z",
     "shell.execute_reply": "2025-05-09T13:27:38.285914Z"
    },
    "papermill": {
     "duration": 0.021304,
     "end_time": "2025-05-09T13:27:38.287417",
     "exception": false,
     "start_time": "2025-05-09T13:27:38.266113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义数据集\n",
    "train_dataset = TensorDataset(Methylation_train, miRNASeq_train, RNAseq_train, labels_tr_tensor)\n",
    "test_dataset = TensorDataset(Methylation_test, miRNASeq_test, RNAseq_test, labels_te_tensor)\n",
    "# val_dataset = TensorDataset(Methylation_val, miRNASeq_val, RNAseq_val, labels_val_tensor)\n",
    "\n",
    "# 定义 DataLoader，使用自定义采样器\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)  # 测试集一般不需要打乱顺序\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)  # 验证集也一般不需要重复采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4bdfa98b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:38.309303Z",
     "iopub.status.busy": "2025-05-09T13:27:38.309064Z",
     "iopub.status.idle": "2025-05-09T13:27:38.326452Z",
     "shell.execute_reply": "2025-05-09T13:27:38.325986Z"
    },
    "papermill": {
     "duration": 0.029597,
     "end_time": "2025-05-09T13:27:38.327549",
     "exception": false,
     "start_time": "2025-05-09T13:27:38.297952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: 153 samples\n",
      "Batch 2: 153 samples\n",
      "Batch 3: 152 samples\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_loader):\n",
    "    print(f\"Batch {i + 1}: {len(batch[0])} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6130e7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:38.349798Z",
     "iopub.status.busy": "2025-05-09T13:27:38.349540Z",
     "iopub.status.idle": "2025-05-09T13:27:38.356907Z",
     "shell.execute_reply": "2025-05-09T13:27:38.356396Z"
    },
    "papermill": {
     "duration": 0.019815,
     "end_time": "2025-05-09T13:27:38.357997",
     "exception": false,
     "start_time": "2025-05-09T13:27:38.338182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: 152 samples\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(test_loader):\n",
    "    print(f\"Batch {i + 1}: {len(batch[0])} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f1cdddd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:38.381102Z",
     "iopub.status.busy": "2025-05-09T13:27:38.380808Z",
     "iopub.status.idle": "2025-05-09T13:27:38.383805Z",
     "shell.execute_reply": "2025-05-09T13:27:38.383311Z"
    },
    "papermill": {
     "duration": 0.016027,
     "end_time": "2025-05-09T13:27:38.384868",
     "exception": false,
     "start_time": "2025-05-09T13:27:38.368841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i, batch in enumerate(val_loader):\n",
    "#     print(f\"Batch {i + 1}: {len(batch[0])} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "409b569a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:38.414311Z",
     "iopub.status.busy": "2025-05-09T13:27:38.414009Z",
     "iopub.status.idle": "2025-05-09T13:27:38.430699Z",
     "shell.execute_reply": "2025-05-09T13:27:38.430149Z"
    },
    "papermill": {
     "duration": 0.036407,
     "end_time": "2025-05-09T13:27:38.432061",
     "exception": false,
     "start_time": "2025-05-09T13:27:38.395654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from typing import Dict, Tuple, List\n",
    "import gc\n",
    "\n",
    "def plot_metrics(lr: float, depth: int, heads: int, dim_head: int, beta: float, adj_parameter: int, dropout: float) -> None:\n",
    "    \"\"\"生成高清训练指标图表\"\"\"\n",
    "    \n",
    "    # ================== 配置参数 ==================\n",
    "    SAVE_DIR = '../../result/BRCA_survival/'\n",
    "    FILE_FORMAT = 'pdf'  # 推荐矢量格式\n",
    "    DPI = 600           # 印刷级分辨率\n",
    "    FONT_CONFIG = {\n",
    "        'font.family': 'DejaVu Sans',  # 跨平台兼容字体\n",
    "        'font.size': 12,\n",
    "        'axes.titlesize': 14,\n",
    "        'axes.labelsize': 12,\n",
    "        'legend.fontsize': 10\n",
    "    }\n",
    "    STYLE_CONFIG = {\n",
    "        'train': {'color': '#E74C3C', 'ls': '-', 'lw': 2.5, 'alpha': 0.9},  # 红色\n",
    "        'val': {'color': '#3498DB', 'ls': '-', 'lw': 2.5, 'alpha': 0.9},    # 蓝色\n",
    "        'test': {'color': '#2ECC71', 'ls': '-', 'lw': 2.5, 'alpha': 0.9}     # 绿色\n",
    "    }\n",
    "    \n",
    "    # ================== 初始化设置 ==================\n",
    "    rcParams.update(FONT_CONFIG)\n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "    param_id = f\"lr{lr:.0e}_depth{depth}heads{heads}dim_head{dim_head}adj_parameter{adj_parameter}dropout{dropout}beta{beta}\".replace('.', '').replace('+', '')\n",
    "\n",
    "    try:\n",
    "        # ================== 创建画布 ==================\n",
    "        fig = plt.figure(figsize=(18, 12), dpi=DPI, facecolor='white')\n",
    "        fig.suptitle(f'Training Metrics ({param_id})', y=1.02, fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # ================== 子图配置 ==================\n",
    "        axes = [\n",
    "            fig.add_subplot(221),  # Loss\n",
    "            fig.add_subplot(222),  # Accuracy\n",
    "            fig.add_subplot(223),  # F1 Score\n",
    "            fig.add_subplot(224)   # AUC\n",
    "        ]\n",
    "        \n",
    "        metric_data = [\n",
    "            ('Loss', (train_losses, test_losses), 'log' if max(train_losses) > 1e3 else 'linear'),\n",
    "            ('Accuracy', (train_accuracies, test_accuracies), 'linear'),\n",
    "            ('F1 Score', (train_f1_scores, test_f1_scores), 'linear'),\n",
    "            ('AUC', (train_auc_scores, test_auc_scores), 'linear')\n",
    "        ]\n",
    "\n",
    "        # ================== 绘制图表 ==================\n",
    "        for ax, (title, (train, test), scale) in zip(axes, metric_data):\n",
    "            # 绘制曲线\n",
    "            ax.plot(train, label='Train', **STYLE_CONFIG['train'])\n",
    "            # ax.plot(val, label='Val', **STYLE_CONFIG['val'])\n",
    "            ax.plot(test, label='Test', **STYLE_CONFIG['test'])\n",
    "            \n",
    "            # 样式设置\n",
    "            ax.set_title(title, pad=15, fontweight='semibold')\n",
    "            ax.set_xlabel('Epochs', labelpad=10)\n",
    "            ax.set_ylabel(title, labelpad=10)\n",
    "            ax.grid(True, which='both', ls='--', alpha=0.4)\n",
    "            ax.set_yscale(scale)\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "            \n",
    "            # 添加图例\n",
    "            if ax == axes[0]:  # 只在第一个子图添加图例\n",
    "                handles, labels = ax.get_legend_handles_labels()\n",
    "                fig.legend(handles, labels, loc='upper center', \n",
    "                          bbox_to_anchor=(0.5, 1.0), ncol=3, frameon=False)\n",
    "\n",
    "        # ================== 布局优化 ==================\n",
    "        plt.tight_layout(pad=3.0, w_pad=2.0, h_pad=2.0)\n",
    "        \n",
    "        # ================== 保存图像 ==================\n",
    "        save_path = os.path.join(SAVE_DIR, f'metrics_{param_id}.{FILE_FORMAT}')\n",
    "        plt.savefig(\n",
    "            save_path,\n",
    "            dpi=DPI,\n",
    "            bbox_inches='tight',\n",
    "            facecolor=fig.get_facecolor(),\n",
    "            edgecolor='none',\n",
    "            transparent=False,\n",
    "            metadata={'CreationDate': None}  # 确保可重复性\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"图表生成失败: {str(e)}\")\n",
    "    finally:\n",
    "        # ================== 资源清理 ==================\n",
    "        plt.close(fig)\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84bfd89f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:38.450018Z",
     "iopub.status.busy": "2025-05-09T13:27:38.449732Z",
     "iopub.status.idle": "2025-05-09T13:27:38.455322Z",
     "shell.execute_reply": "2025-05-09T13:27:38.454881Z"
    },
    "papermill": {
     "duration": 0.014153,
     "end_time": "2025-05-09T13:27:38.456020",
     "exception": false,
     "start_time": "2025-05-09T13:27:38.441867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(data_loader, model, optimizer, adj_parameter, output_attentions=False):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    all_probs, all_labels = [], []\n",
    "\n",
    "    for batch in data_loader:\n",
    "        Methylation_batch, miRNASeq_batch, RNAseq_batch, labels_batch = [\n",
    "            tensor.to(device) for tensor in batch\n",
    "        ]\n",
    "\n",
    "        # 生成三维邻接张量\n",
    "        graph_train = np.stack([\n",
    "            gen_trte_adj_mat(Methylation_batch.cpu(), adj_parameter),\n",
    "            gen_trte_adj_mat(miRNASeq_batch.cpu(), adj_parameter),\n",
    "            gen_trte_adj_mat(RNAseq_batch.cpu(), adj_parameter)\n",
    "        ], axis=-1)\n",
    "        graph_train = torch.from_numpy(graph_train).float().to(device).permute(0, 2, 1)\n",
    "\n",
    "        # 梯度更新流程\n",
    "        optimizer.zero_grad()\n",
    "        ci_loss, ci = model(\n",
    "            Methylation_batch, \n",
    "            miRNASeq_batch,\n",
    "            RNAseq_batch,\n",
    "            graph_train,\n",
    "            labels_batch,\n",
    "            output_attentions=output_attentions\n",
    "        )\n",
    "        ci_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 结果收集\n",
    "        total_loss += ci_loss.item() * labels_batch.size(0)\n",
    "        all_probs.append(F.softmax(ci, dim=1).detach().cpu().numpy())\n",
    "        all_labels.append(labels_batch.detach().cpu().numpy().flatten())\n",
    "\n",
    "    return (\n",
    "        total_loss / len(data_loader.dataset),\n",
    "        np.concatenate(all_probs),\n",
    "        np.concatenate(all_labels)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e66ebda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:38.472958Z",
     "iopub.status.busy": "2025-05-09T13:27:38.472728Z",
     "iopub.status.idle": "2025-05-09T13:27:38.475563Z",
     "shell.execute_reply": "2025-05-09T13:27:38.475164Z"
    },
    "papermill": {
     "duration": 0.012992,
     "end_time": "2025-05-09T13:27:38.476169",
     "exception": false,
     "start_time": "2025-05-09T13:27:38.463177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def val_epoch(data_loader, model, adj_parameter, output_attentions=False):\n",
    "#     model.eval()\n",
    "#     total_loss = 0.0\n",
    "#     all_labels, all_probs = [], []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for batch in data_loader:\n",
    "#             # 数据预处理\n",
    "#             Methylation_batch, miRNASeq_batch, RNAseq_batch, labels_batch = [\n",
    "#                 x.to(device) for x in batch\n",
    "#             ]\n",
    "#             # print(miRNASeq_batch.shape) #torch.Size([32, 217])\n",
    "#             # 生成三维邻接张量\n",
    "#             graph_val = torch.from_numpy(np.stack([\n",
    "#                 gen_trte_adj_mat(d.cpu(), adj_parameter) \n",
    "#                 for d in [Methylation_batch, miRNASeq_batch, RNAseq_batch]\n",
    "#             ], axis=-1)).float().to(device).permute(0,2,1)\n",
    "\n",
    "#             # 前向计算\n",
    "#             ci_loss, ci = model(\n",
    "#                 Methylation_batch, \n",
    "#                 miRNASeq_batch,\n",
    "#                 RNAseq_batch,\n",
    "#                 graph_val,\n",
    "#                 labels_batch,\n",
    "#                 output_attentions=output_attentions\n",
    "#             )\n",
    "\n",
    "#             # 累计结果\n",
    "#             total_loss += ci_loss.item() * labels_batch.size(0)\n",
    "#             all_probs.append(F.softmax(ci, 1).detach().cpu().numpy())\n",
    "#             all_labels.append(labels_batch.detach().cpu().numpy().flatten())\n",
    "\n",
    "#     return (\n",
    "#         total_loss / len(data_loader.dataset),\n",
    "#         np.concatenate(all_probs),\n",
    "#         np.concatenate(all_labels)\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a309d1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:38.490972Z",
     "iopub.status.busy": "2025-05-09T13:27:38.490598Z",
     "iopub.status.idle": "2025-05-09T13:27:38.495836Z",
     "shell.execute_reply": "2025-05-09T13:27:38.495443Z"
    },
    "papermill": {
     "duration": 0.013226,
     "end_time": "2025-05-09T13:27:38.496460",
     "exception": false,
     "start_time": "2025-05-09T13:27:38.483234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_epoch(data_loader, model, adj_parameter, output_attentions=False):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_probs, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            # 数据预处理 (保持原始变量名)\n",
    "            Methylation_batch, miRNASeq_batch, RNAseq_batch, labels_test_tensor = [\n",
    "                tensor.to(device) for tensor in batch\n",
    "            ]\n",
    "\n",
    "            # 生成邻接矩阵 (保持原始逻辑但更紧凑)\n",
    "            graph_test = torch.from_numpy(\n",
    "                np.stack([\n",
    "                    gen_trte_adj_mat(Methylation_batch.cpu(), adj_parameter),\n",
    "                    gen_trte_adj_mat(miRNASeq_batch.cpu(), adj_parameter),\n",
    "                    gen_trte_adj_mat(RNAseq_batch.cpu(), adj_parameter)\n",
    "                ], axis=-1)\n",
    "            ).float().to(device).permute(0, 2, 1)\n",
    "\n",
    "            # 前向计算\n",
    "            loss, logits = model(\n",
    "                Methylation_batch,\n",
    "                miRNASeq_batch,\n",
    "                RNAseq_batch,\n",
    "                graph_test,\n",
    "                labels_test_tensor,\n",
    "                output_attentions=output_attentions\n",
    "            )\n",
    "\n",
    "            # 结果收集\n",
    "            total_loss += loss.item() * labels_test_tensor.size(0)\n",
    "            all_probs.append(F.softmax(logits, dim=1).detach().cpu().numpy())\n",
    "            all_labels.append(labels_test_tensor.detach().cpu().numpy().flatten())\n",
    "\n",
    "    return (\n",
    "        total_loss / len(data_loader.dataset),\n",
    "        np.concatenate(all_probs),\n",
    "        np.concatenate(all_labels)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a07e129",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:38.513077Z",
     "iopub.status.busy": "2025-05-09T13:27:38.512884Z",
     "iopub.status.idle": "2025-05-09T13:27:38.523581Z",
     "shell.execute_reply": "2025-05-09T13:27:38.523203Z"
    },
    "papermill": {
     "duration": 0.020762,
     "end_time": "2025-05-09T13:27:38.524182",
     "exception": false,
     "start_time": "2025-05-09T13:27:38.503420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 用于保存指标数据的列表\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "val_accuracies = []\n",
    "val_f1_scores = []\n",
    "val_auc_scores = []\n",
    "test_accuracies = []\n",
    "test_f1_scores = []\n",
    "test_auc_scores = []\n",
    "train_accuracies = []\n",
    "train_f1_scores = []\n",
    "train_auc_scores = []\n",
    "\n",
    "def train_test(\n",
    "        Methylation_train,\n",
    "        miRNASeq_train,\n",
    "        RNAseq_train,\n",
    "        lr,\n",
    "        depth, \n",
    "        heads, \n",
    "        dim_head,\n",
    "        beta, \n",
    "        attn_dropout,\n",
    "        ff_dropout, \n",
    "        classifier_dropout,\n",
    "        adj_parameter,\n",
    "        num_epoch_pretrain\n",
    "):\n",
    "    # 初始化最佳指标跟踪器\n",
    "    best_metrics = {\n",
    "        'epoch': -1,\n",
    "        'test_acc': 0.0,\n",
    "        'test_f1': 0.0,\n",
    "        'test_auc': 0.0,\n",
    "    }\n",
    "    \n",
    "    DEPTH = depth\n",
    "    HEAD = heads\n",
    "    HEAD_DIM = dim_head\n",
    "\n",
    "    classifier_input = [Methylation_train.shape[1], miRNASeq_train.shape[1], RNAseq_train.shape[1]]\n",
    "    classifier_dim = [\n",
    "        [classifier_input[0], 300, 200],\n",
    "        [classifier_input[1], 300, 200],\n",
    "        [classifier_input[2], 300, 200]\n",
    "    ]\n",
    "    col_dim = 32\n",
    "\n",
    "    # 确定 row_dim 和 embeding_num\n",
    "    if num_view <= 2:\n",
    "        embeding = True\n",
    "        embeding_num = 32\n",
    "        row_dim = embeding_num  # 请根据需要修改此处\n",
    "    else:\n",
    "        embeding = False\n",
    "        row_dim = num_view\n",
    "        embeding_num = 32\n",
    "    \n",
    "    model = pathformer_model(\n",
    "        row_dim=row_dim,\n",
    "        col_dim=col_dim,\n",
    "        depth=DEPTH,\n",
    "        heads=HEAD,\n",
    "        dim_head=HEAD_DIM,\n",
    "        classifier_input=classifier_input,\n",
    "        classifier_dim=classifier_dim,\n",
    "        label_dim=label_dim,\n",
    "        embeding=embeding,\n",
    "        embeding_num=embeding_num,\n",
    "        beta=beta,\n",
    "        attn_dropout=attn_dropout,\n",
    "        ff_dropout=ff_dropout,\n",
    "        classifier_dropout=classifier_dropout,\n",
    "        num_view=num_view,\n",
    "        dim_hvcdn=dim_hvcdn\n",
    "    )\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model.to(device)\n",
    "\n",
    "    logging.info(\"\\nPretrain GCNs...\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    logging.info(\"\\nTraining...\")\n",
    "    for epoch in range(num_epoch_pretrain + 1):\n",
    "        # 每一轮都进行训练\n",
    "        train_loss, train_probs, labels_train_tensor = train_epoch(train_loader, model, optimizer, adj_parameter, output_attentions=False)\n",
    "        train_acc = accuracy_score(labels_train_tensor, train_probs.argmax(1))\n",
    "        train_f1 = f1_score(labels_train_tensor, train_probs.argmax(1))\n",
    "        train_auc = roc_auc_score(labels_train_tensor, train_probs[:, 1])\n",
    "\n",
    "        logging.info(f\"Train Epoch {epoch}, Loss: {train_loss}\")\n",
    "        logging.info(f\"Train Epoch {epoch}, ACC: Train ACC: {train_acc:.3f}\")\n",
    "        logging.info(f\"Train Epoch {epoch}, f1: Train F1: {train_f1:.3f}\")\n",
    "        logging.info(f\"Train Epoch {epoch}, AUC: Train AUC: {train_auc:.3f}\")\n",
    "        \n",
    "        # 每一轮都进行验证\n",
    "        # val_loss, val_probs, labels_validation_tensor = val_epoch(val_loader, model, adj_parameter, output_attentions=False)\n",
    "        # val_acc = accuracy_score(labels_validation_tensor, val_probs.argmax(1))\n",
    "        # val_f1 = f1_score(labels_validation_tensor, val_probs.argmax(1))\n",
    "        # val_auc = roc_auc_score(labels_validation_tensor, val_probs[:, 1])\n",
    "        # logging.info(f\"val Epoch {epoch}, Loss: {val_loss}\")\n",
    "        # logging.info(f\"val Epoch {epoch}, ACC: val ACC: {val_acc:.3f}\")\n",
    "        # logging.info(f\"val Epoch {epoch}, f1: val F1: {val_f1:.3f}\")\n",
    "        # logging.info(f\"val Epoch {epoch}, AUC: val AUC: {val_auc:.3f}\")\n",
    "        \n",
    "        # 每一轮都进行测试\n",
    "        test_loss, test_probs, labels_test_tensor = test_epoch(test_loader, model, adj_parameter, output_attentions=False)\n",
    "        test_acc = accuracy_score(labels_test_tensor, test_probs.argmax(1))\n",
    "        test_f1 = f1_score(labels_test_tensor, test_probs.argmax(1))\n",
    "        test_auc = roc_auc_score(labels_test_tensor, test_probs[:, 1])\n",
    "        logging.info(f\"test Epoch {epoch}, Loss: {test_loss}\")\n",
    "        logging.info(f\"test Epoch {epoch}, ACC: test ACC: {test_acc:.3f}\")\n",
    "        logging.info(f\"test Epoch {epoch}, f1: test F1: {test_f1:.3f}\")\n",
    "        logging.info(f\"test Epoch {epoch}, AUC: test AUC: {test_auc:.3f}\")\n",
    "\n",
    "        # 更新最佳指标 (以验证AUC为选择标准)\n",
    "        if test_auc > best_metrics['test_auc'] or \\\n",
    "           (test_auc == best_metrics['test_auc'] and test_f1 > best_metrics['test_f1']):\n",
    "            best_metrics.update({\n",
    "                'epoch': epoch,\n",
    "                'test_acc': test_acc,\n",
    "                'test_f1': test_f1,\n",
    "                'test_auc': test_auc\n",
    "            })\n",
    "\n",
    "        logging.info(\"\\n\")\n",
    "\n",
    "        # 保存训练指标\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        train_f1_scores.append(train_f1)\n",
    "        train_auc_scores.append(train_auc)\n",
    "        \n",
    "        # val_losses.append(val_loss)\n",
    "        # val_accuracies.append(val_acc)\n",
    "        # val_f1_scores.append(val_f1)\n",
    "        # val_auc_scores.append(val_auc)\n",
    "        \n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_acc)\n",
    "        test_f1_scores.append(test_f1)\n",
    "        test_auc_scores.append(test_auc)\n",
    "\n",
    "        # 绘制并保存指标图\n",
    "        plot_metrics(lr, depth, heads, dim_head, beta, adj_parameter, dropout=attn_dropout)\n",
    "\n",
    "    return (\n",
    "        best_metrics['test_acc'],\n",
    "        best_metrics['test_f1'],\n",
    "        best_metrics['test_auc']\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e819324a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:38.539123Z",
     "iopub.status.busy": "2025-05-09T13:27:38.538934Z",
     "iopub.status.idle": "2025-05-09T13:27:38.543046Z",
     "shell.execute_reply": "2025-05-09T13:27:38.542675Z"
    },
    "papermill": {
     "duration": 0.012153,
     "end_time": "2025-05-09T13:27:38.543664",
     "exception": false,
     "start_time": "2025-05-09T13:27:38.531511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 用于保存指标数据的列表\n",
    "# train_losses = []\n",
    "# val_losses = []\n",
    "# test_losses = []\n",
    "# val_accuracies = []\n",
    "# val_f1_scores = []\n",
    "# val_auc_scores = []\n",
    "# test_accuracies = []\n",
    "# test_f1_scores = []\n",
    "# test_auc_scores = []\n",
    "# train_accuracies = []\n",
    "# train_f1_scores = []\n",
    "# train_auc_scores = []\n",
    "# train_c_index = []\n",
    "# val_c_index = []\n",
    "# test_c_index = []\n",
    "\n",
    "# def train_test(\n",
    "#         Methylation_train,\n",
    "#         Methylation_test,\n",
    "#         miRNASeq_train,\n",
    "#         miRNASeq_test,\n",
    "#         RNAseq_train,\n",
    "#         RNAseq_test,\n",
    "#         label_train,\n",
    "#         label_test, \n",
    "#         labels_tr_tensor,\n",
    "#         lr,\n",
    "#         depth, \n",
    "#         heads, \n",
    "#         dim_head,\n",
    "#         beta, \n",
    "#         attn_dropout,\n",
    "#         ff_dropout, \n",
    "#         classifier_dropout,\n",
    "#         adj_parameter,\n",
    "#         num_epoch_pretrain\n",
    "# ):\n",
    "    \n",
    "#     DEPTH = depth\n",
    "#     HEAD = heads\n",
    "#     HEAD_DIM = dim_head\n",
    "\n",
    "#     classifier_input = [Methylation_train.shape[1], miRNASeq_train.shape[1], RNAseq_train.shape[1]]\n",
    "#     classifier_dim = [\n",
    "#         [classifier_input[0], 300, 200],\n",
    "#         [classifier_input[1], 300, 200],\n",
    "#         [classifier_input[2], 300, 200]\n",
    "#     ]\n",
    "#     col_dim = 71\n",
    "\n",
    "#     # 确定 row_dim 和 embeding_num\n",
    "#     if num_view <= 2:\n",
    "#         embeding = True\n",
    "#         embeding_num = 71\n",
    "#         row_dim = embeding_num  # 请根据需要修改此处\n",
    "#     else:\n",
    "#         embeding = False\n",
    "#         row_dim = num_view\n",
    "#         embeding_num = 71\n",
    "    \n",
    "#     model = pathformer_model(\n",
    "#         row_dim=row_dim,\n",
    "#         col_dim=col_dim,\n",
    "#         depth=DEPTH,\n",
    "#         heads=HEAD,\n",
    "#         dim_head=HEAD_DIM,\n",
    "#         classifier_input=classifier_input,\n",
    "#         classifier_dim=classifier_dim,\n",
    "#         label_dim=label_dim,\n",
    "#         embeding=embeding,\n",
    "#         embeding_num=embeding_num,\n",
    "#         beta=beta,\n",
    "#         attn_dropout=attn_dropout,\n",
    "#         ff_dropout=ff_dropout,\n",
    "#         classifier_dropout=classifier_dropout,\n",
    "#         num_view=num_view,\n",
    "#         dim_hvcdn=dim_hvcdn\n",
    "#     )\n",
    "\n",
    "#     if torch.cuda.is_available():\n",
    "#         model.to(device)\n",
    "\n",
    "#     print(\"\\nPretrain GCNs...\")\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "#     print(\"\\nTraining...\")\n",
    "#     for epoch in range(num_epoch_pretrain + 1):\n",
    "#         # 每一轮都进行训练\n",
    "#         train_loss, train_probs, labels_train_tensor = train_epoch(train_loader, model, optimizer, adj_parameter, epoch, output_attentions=False)\n",
    "#         train_acc = accuracy_score(labels_train_tensor, train_probs.argmax(1))\n",
    "#         train_f1 = f1_score(labels_train_tensor, train_probs.argmax(1))\n",
    "#         train_auc = roc_auc_score(labels_train_tensor, train_probs[:, 1])\n",
    "# #         print(f\"Train Epoch {epoch}, Loss: {train_loss}\")\n",
    "# #         print(f\"Train Epoch {epoch}, ACC: Train ACC: {train_acc:.3f}\")\n",
    "# #         print(f\"Train Epoch {epoch}, f1: Train F1: {train_f1:.3f}\")\n",
    "# #         print(f\"Train Epoch {epoch}, AUC: Train AUC: {train_auc:.3f}\")\n",
    "        \n",
    "#         # 每一轮都进行验证\n",
    "#         val_loss, val_probs, labels_val_tensor = val_epoch(val_loader, model, adj_parameter, epoch, output_attentions=False)\n",
    "#         val_acc = accuracy_score(labels_val_tensor, val_probs.argmax(1))\n",
    "#         val_f1 = f1_score(labels_val_tensor, val_probs.argmax(1))\n",
    "#         val_auc = roc_auc_score(labels_val_tensor, val_probs[:, 1])\n",
    "# #         print(f\"val Epoch {epoch}, Loss: {val_loss}\")\n",
    "# #         print(f\"val Epoch {epoch}, ACC: val ACC: {val_acc:.3f}\")\n",
    "# #         print(f\"val Epoch {epoch}, f1: val F1: {val_f1:.3f}\")\n",
    "# #         print(f\"val Epoch {epoch}, AUC: val AUC: {val_auc:.3f}\")\n",
    "        \n",
    "#         # 每一轮都进行测试\n",
    "#         test_loss, test_probs, labels_test_tensor = test_epoch(test_loader, model, adj_parameter, epoch, output_attentions=False)\n",
    "#         test_acc = accuracy_score(labels_test_tensor, test_probs.argmax(1))\n",
    "#         test_f1 = f1_score(labels_test_tensor, test_probs.argmax(1))\n",
    "#         test_auc = roc_auc_score(labels_test_tensor, test_probs[:, 1])\n",
    "# #         print(f\"test Epoch {epoch}, Loss: {test_loss}\")\n",
    "# #         print(f\"test Epoch {epoch}, ACC: test ACC: {test_acc:.3f}\")\n",
    "# #         print(f\"test Epoch {epoch}, f1: test F1: {test_f1:.3f}\")\n",
    "# #         print(f\"test Epoch {epoch}, AUC: test AUC: {test_auc:.3f}\")\n",
    "\n",
    "#         print(\"\\n\")\n",
    "\n",
    "#         # 保存训练指标\n",
    "#         train_losses.append(train_loss)\n",
    "#         train_accuracies.append(train_acc)\n",
    "#         train_f1_scores.append(train_f1)\n",
    "#         train_auc_scores.append(train_auc)\n",
    "        \n",
    "#         val_losses.append(val_loss)\n",
    "#         val_accuracies.append(val_acc)\n",
    "#         val_f1_scores.append(val_f1)\n",
    "#         val_auc_scores.append(val_auc)\n",
    "        \n",
    "#         test_losses.append(test_loss)\n",
    "#         test_accuracies.append(test_acc)\n",
    "#         test_f1_scores.append(test_f1)\n",
    "#         test_auc_scores.append(test_auc)\n",
    "\n",
    "#         # 绘制并保存指标图\n",
    "#         plot_metrics(lr, depth, heads, dim_head, beta, dropout=attn_dropout)\n",
    "\n",
    "#     # 返回最终的预测结果和指标\n",
    "#     final_predictions = test_probs.argmax(1)\n",
    "#     return final_predictions, test_acc, test_f1, test_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dccd421e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T13:27:38.558391Z",
     "iopub.status.busy": "2025-05-09T13:27:38.558246Z"
    },
    "papermill": {
     "duration": 576.756579,
     "end_time": "2025-05-09T13:37:15.307323",
     "exception": false,
     "start_time": "2025-05-09T13:27:38.550744",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# 配置日志和路径\n",
    "LOG_FILE = '../../result/BRCA_survival/training_log_CMFM.txt'\n",
    "RESULT_FILE = '../../result/BRCA_survival/mogat_training_results.xlsx'\n",
    "os.makedirs(os.path.dirname(LOG_FILE), exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=LOG_FILE,\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(message)s',\n",
    "    filemode='w'  # 每次运行覆盖旧日志\n",
    ")\n",
    "\n",
    "# 超参数配置（便于维护和修改）\n",
    "HP_CONFIG = {\n",
    "    'lr': [0.0001, 0.001, 0.01],\n",
    "    'depth': [2, 3, 4, 6],\n",
    "    'heads': [4, 6, 8],\n",
    "    'dim_head': [12, 16, 32, 64],\n",
    "    'dropout': [0.3],\n",
    "    'beta': [1],\n",
    "    'adj_parameter': [2, 4, 6, 8, 10]\n",
    "}\n",
    "\n",
    "# 计算总组合数\n",
    "total_combinations = (\n",
    "    len(HP_CONFIG['lr']) *\n",
    "    len(HP_CONFIG['depth']) *\n",
    "    len(HP_CONFIG['heads']) *\n",
    "    len(HP_CONFIG['dim_head']) *\n",
    "    len(HP_CONFIG['dropout']) *\n",
    "    len(HP_CONFIG['beta']) *\n",
    "    len(HP_CONFIG['adj_parameter'])\n",
    ")\n",
    "\n",
    "# 结果缓存配置\n",
    "BATCH_SIZE = 5  # 每5个结果写入一次文件\n",
    "results_cache = []\n",
    "\n",
    "def save_results(batch: list, force_save: bool = False):\n",
    "    \"\"\"批量保存结果到文件\"\"\"\n",
    "    if not force_save and len(batch) < BATCH_SIZE:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        df = pd.DataFrame(batch)\n",
    "        header = not os.path.exists(RESULT_FILE)\n",
    "        \n",
    "        with pd.ExcelWriter(\n",
    "            RESULT_FILE,\n",
    "            mode='a' if os.path.exists(RESULT_FILE) else 'w',\n",
    "            engine='openpyxl',\n",
    "            if_sheet_exists='overlay' if os.path.exists(RESULT_FILE) else None\n",
    "        ) as writer:\n",
    "            df.to_excel(\n",
    "                writer,\n",
    "                index=False,\n",
    "                sheet_name='Results',\n",
    "                header=header,\n",
    "                startrow=writer.sheets['Results'].max_row if not header else 0\n",
    "            )\n",
    "        batch.clear()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"保存结果失败: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# 主训练循环\n",
    "current_combination = 0\n",
    "start_total = time.time()\n",
    "\n",
    "try:\n",
    "    for lr in HP_CONFIG['lr']:\n",
    "        for depth in HP_CONFIG['depth']:\n",
    "            for heads in HP_CONFIG['heads']:\n",
    "                for dim_head in HP_CONFIG['dim_head']:\n",
    "                    for dropout in HP_CONFIG['dropout']:\n",
    "                        for beta in HP_CONFIG['beta']:\n",
    "                            for adj_param in HP_CONFIG['adj_parameter']:\n",
    "                                current_combination += 1\n",
    "                                start_iter = time.time()\n",
    "                                \n",
    "                                # 日志记录当前参数\n",
    "                                param_str = (\n",
    "                                    f\"lr={lr}, depth={depth}, heads={heads}, \"\n",
    "                                    f\"dim_head={dim_head}, dropout={dropout}, \"\n",
    "                                    f\"beta={beta}, adj_parameter={adj_param} \"\n",
    "                                    f\"({current_combination}/{total_combinations})\"\n",
    "                                )\n",
    "                                logging.info(f\"开始训练: {param_str}\")\n",
    "\n",
    "                                try:\n",
    "                                    # 执行训练\n",
    "                                    acc, f1, auc = train_test(\n",
    "                                        Methylation_train=Methylation_train,\n",
    "                                        miRNASeq_train=miRNASeq_train,\n",
    "                                        RNAseq_train=RNAseq_train,\n",
    "                                        lr=lr,\n",
    "                                        depth=depth,\n",
    "                                        heads=heads,\n",
    "                                        dim_head=dim_head,\n",
    "                                        beta=beta,\n",
    "                                        attn_dropout=dropout,\n",
    "                                        ff_dropout=dropout,\n",
    "                                        classifier_dropout=dropout,\n",
    "                                        adj_parameter=adj_param,\n",
    "                                        num_epoch_pretrain=1500\n",
    "                                    )\n",
    "\n",
    "                                    # 缓存结果\n",
    "                                    results_cache.append({\n",
    "                                        'lr': lr,\n",
    "                                        'depth': depth,\n",
    "                                        'heads': heads,\n",
    "                                        'dim_head': dim_head,\n",
    "                                        'dropout': dropout,\n",
    "                                        'beta': beta,\n",
    "                                        'adj_parameter': adj_param,\n",
    "                                        'accuracy': acc,\n",
    "                                        'f1_score': f1,\n",
    "                                        'auc': auc\n",
    "                                    })\n",
    "\n",
    "                                    # 定期保存\n",
    "                                    save_results(results_cache)\n",
    "\n",
    "                                    # 记录成功信息\n",
    "                                    elapsed = time.time() - start_iter\n",
    "                                    logging.info(\n",
    "                                        f\"完成: {param_str} | \"\n",
    "                                        f\"耗时: {elapsed:.1f}s | \"\n",
    "                                        f\"结果: ACC={acc:.4f}, F1={f1:.4f}, AUC={auc:.4f}\"\n",
    "                                    )\n",
    "\n",
    "                                except torch.cuda.OutOfMemoryError:\n",
    "                                    logging.warning(f\"显存不足，跳过组合: {param_str}\")\n",
    "                                    torch.cuda.empty_cache()\n",
    "                                except Exception as e:\n",
    "                                    logging.error(f\"训练失败: {param_str} | 错误: {str(e)}\")\n",
    "                                    continue\n",
    "                                # 用于保存指标数据的列表\n",
    "                                train_losses = []\n",
    "                                val_losses = []\n",
    "                                test_losses = []\n",
    "                                val_accuracies = []\n",
    "                                val_f1_scores = []\n",
    "                                val_auc_scores = []\n",
    "                                test_accuracies = []\n",
    "                                test_f1_scores = []\n",
    "                                test_auc_scores = []\n",
    "                                train_accuracies = []\n",
    "                                train_f1_scores = []\n",
    "                                train_auc_scores = []\n",
    "\n",
    "    # 最后强制保存剩余结果\n",
    "    save_results(results_cache, force_save=True)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    logging.warning(\"用户中断训练，保存已完成的实验结果...\")\n",
    "    save_results(results_cache, force_save=True)\n",
    "finally:\n",
    "    total_time = time.time() - start_total\n",
    "    logging.info(f\"全部完成! 总耗时: {total_time/3600:.2f} 小时\")\n",
    "\n",
    "print(\"实验完成，结果保存在:\", RESULT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7c5f32",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import time\n",
    "# import pandas as pd\n",
    "# from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# # 创建一个 DataFrame 用于存储结果\n",
    "# results_df = pd.DataFrame(columns=['lr', 'depth', 'heads', 'dim_head', 'dropout', 'beta', 'accuracy', 'f1_score', 'auc'])\n",
    "\n",
    "# # 设置单一的超参数组合\n",
    "# lr = 0.0001  # 你想要的学习率\n",
    "# depth = 6  # 你想要的层数\n",
    "# heads = 4  # 你想要的注意力头数\n",
    "# dim_head = 32  # 你想要的注意力头的维度\n",
    "# dropout = 0.5  # 你想要的 dropout 比例\n",
    "# beta = 1  # 你想要的 beta 值\n",
    "\n",
    "# # 训练参数组合\n",
    "# start_time = time.time()  # 记录开始时间\n",
    "# print(f\"训练参数：lr={lr}, depth={depth}, heads={heads}, \"\n",
    "#       f\"dim_head={dim_head}, dropout={dropout}, beta={beta}\")\n",
    "\n",
    "# # 训练函数假设已定义，返回最后的预测和各项指标\n",
    "# try:\n",
    "#     last_predictions, acc, f1, auc = train_test(\n",
    "#         Methylation_train=Methylation_train,\n",
    "#         Methylation_test=Methylation_test,\n",
    "#         miRNASeq_train=miRNASeq_train,\n",
    "#         miRNASeq_test=miRNASeq_test,\n",
    "#         RNAseq_train=RNAseq_train,\n",
    "#         RNAseq_test=RNAseq_test,\n",
    "#         label_train=labels_train,\n",
    "#         label_test=labels_test,\n",
    "#         labels_tr_tensor=labels_tr_tensor,\n",
    "#         lr=lr,\n",
    "#         depth=depth,\n",
    "#         heads=heads,\n",
    "#         dim_head=dim_head,\n",
    "#         beta=beta,\n",
    "#         attn_dropout=dropout,\n",
    "#         ff_dropout=dropout,\n",
    "#         classifier_dropout=dropout,\n",
    "#         num_epoch_pretrain=2000,\n",
    "#     )\n",
    "\n",
    "#     # 清空列表以便下一个超参数组合使用\n",
    "#     train_losses = []\n",
    "#     val_losses = []\n",
    "#     test_losses = []\n",
    "    \n",
    "#     train_accuracies = []\n",
    "#     val_accuracies = []\n",
    "#     test_accuracies = []\n",
    "    \n",
    "#     train_f1_scores = []\n",
    "#     val_f1_scores = []\n",
    "#     test_f1_scores = []\n",
    "    \n",
    "#     train_auc_scores = []\n",
    "#     val_auc_scores = []\n",
    "#     test_auc_scores = []\n",
    "    \n",
    "#     # 检查最后的预测结果是否全部一致\n",
    "#     if last_predictions is not None:\n",
    "#         last_predictions_tensor = torch.tensor(last_predictions)  # 转换为张量\n",
    "#         if not torch.all(last_predictions_tensor == last_predictions_tensor[0]):\n",
    "#             print(\"最后一轮的预测结果不一致，保存该参数组合和评价指标。\")\n",
    "            \n",
    "#             # 保存结果到 DataFrame\n",
    "#             result = {\n",
    "#                 'lr': lr,\n",
    "#                 'depth': depth,\n",
    "#                 'heads': heads,\n",
    "#                 'dim_head': dim_head,\n",
    "#                 'dropout': dropout,\n",
    "#                 'beta': beta,\n",
    "#                 'accuracy': acc,\n",
    "#                 'f1_score': f1,\n",
    "#                 'auc': auc\n",
    "#             }\n",
    "\n",
    "#             result_df = pd.DataFrame([result])\n",
    "\n",
    "#             # 确保 result_df 不为空且不全为 NA\n",
    "#             if result_df.notnull().any().any():\n",
    "#                 results_df = pd.concat([results_df, result_df], ignore_index=True)\n",
    "\n",
    "#                 # 检查 Excel 文件是否存在，如果不存在则创建\n",
    "#                 if not os.path.isfile('../../result/BRCA_survival/mogat_training_results.xlsx'):\n",
    "#                     results_df.to_excel('../../result/BRCA_survival/mogat_training_results.xlsx', index=False, sheet_name='Results')\n",
    "#                 else:\n",
    "#                     # 立即写入 Excel 文件\n",
    "#                     with pd.ExcelWriter('../../result/BRCA_survival/mogat_training_results.xlsx', mode='a', engine='openpyxl', if_sheet_exists='overlay') as writer:\n",
    "#                         results_df.to_excel(writer, index=False, sheet_name='Results', startrow=writer.sheets['Results'].max_row)\n",
    "#         else:\n",
    "#             print(\"最后一轮的预测结果全部一致，不保存该参数组合。\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"训练参数组合 lr={lr}, depth={depth}, heads={heads}, dim_head={dim_head}, dropout={dropout}, beta={beta} 时发生错误: {e}\")\n",
    "\n",
    "# elapsed_time = time.time() - start_time\n",
    "# print(f\"训练完成，耗时: {elapsed_time:.2f} 秒\")\n",
    "\n",
    "# # 最终保存（如果需要）\n",
    "# if not results_df.empty:\n",
    "#     results_df.to_excel('../../result/BRCA_survival/mogat_training_results.xlsx', index=False, sheet_name='Results')\n",
    "#     print(\"参数组合和评价指标已保存为 mogat_training_results.xlsx 文件。\")\n",
    "# else:\n",
    "#     print(\"没有符合条件的参数组合，未保存任何结果。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 582.984626,
   "end_time": "2025-05-09T13:37:16.333050",
   "environment_variables": {},
   "exception": null,
   "input_path": "train_test_CMFM.ipynb",
   "output_path": "output_CMFM.ipynb",
   "parameters": {},
   "start_time": "2025-05-09T13:27:33.348424",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}