{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99bf365e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from network.ipynb\n",
      "importing Jupyter notebook from utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import KNNImputer\n",
    "import torch.nn.functional as F\n",
    "import import_ipynb\n",
    "import network\n",
    "from torch.nn import Parameter\n",
    "from torch.nn.init import xavier_normal_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ca907b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82b2413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance_torch(x1, x2=None, eps=1e-8):\n",
    "    x2 = x1 if x2 is None else x2\n",
    "    w1 = x1.norm(p=2, dim=1, keepdim=True)\n",
    "    w2 = w1 if x2 is x1 else x2.norm(p=2, dim=1, keepdim=True)\n",
    "    return 1 - torch.mm(x1, x2.t()) / (w1 * w2.t()).clamp(min=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22fe221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_adj_mat_parameter(edge_per_node, data, metric=\"cosine\"):\n",
    "    assert metric == \"cosine\", \"Only cosine distance implemented\"\n",
    "    dist = cosine_distance_torch(data, data)\n",
    "    parameter = torch.sort(dist.reshape(-1,)).values[edge_per_node*data.shape[0]]\n",
    "    return np.squeeze(parameter.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa6f22f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_from_dist_tensor(dist, parameter, self_dist=True):\n",
    "    if self_dist:\n",
    "        assert dist.shape[0] == dist.shape[1], \"Input is not pairwise dist matrix\"\n",
    "\n",
    "    # 将 NumPy 数组转换为 PyTorch 张量\n",
    "    dist_tensor = dist.clone().detach()\n",
    "    parameter_tensor = torch.tensor(parameter)  # 将参数也转换为 PyTorch 张量\n",
    "\n",
    "    # 在进行比较操作时，确保使用 PyTorch 的方法\n",
    "    g = (dist_tensor <= parameter_tensor).float()\n",
    "\n",
    "    if self_dist:\n",
    "        diag_idx = torch.arange(g.shape[0])\n",
    "        g[diag_idx, diag_idx] = 0\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3578e684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_adj_mat_tensor(data, parameter, metric=\"cosine\"):\n",
    "    assert metric == \"cosine\", \"Only cosine distance implemented\"\n",
    "    dist = cosine_distance_torch(data, data)\n",
    "    g = graph_from_dist_tensor(dist, parameter, self_dist=True)\n",
    "    if metric == \"cosine\":\n",
    "        adj = 1-dist\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    adj = adj*g \n",
    "    adj_T = adj.transpose(0,1)\n",
    "    I = torch.eye(adj.shape[0])\n",
    "    adj = adj + adj_T*(adj_T > adj).float() - adj*(adj_T > adj).float()\n",
    "    adj = F.normalize(adj + I, p=1)\n",
    "    \n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20cd4273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_trte_adj_mat(X_train, adj_parameter):\n",
    "    adj_metric = \"cosine\" # cosine distance\n",
    "    adj_train = []\n",
    "    adj_parameter_adaptive = cal_adj_mat_parameter(adj_parameter, X_train, adj_metric)\n",
    "    adj_train = gen_adj_mat_tensor(X_train, adj_parameter_adaptive, adj_metric)\n",
    "    \n",
    "    return adj_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a258cfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_sample_weight(labels, num_class, use_sample_weight=True):\n",
    "    labels_np = labels.numpy()  # 将 PyTorch 张量转换为 NumPy 数组\n",
    "    if not use_sample_weight:\n",
    "        return np.ones(len(labels_np)) / len(labels_np)\n",
    "    count = np.zeros(num_class)\n",
    "    for i in range(num_class):\n",
    "        count[i] = np.sum(labels_np == i)\n",
    "    sample_weight = np.zeros(labels_np.shape)\n",
    "    for i in range(num_class):\n",
    "        sample_weight[np.where(labels_np == i)[0]] = count[i] / len(labels_np)\n",
    "    return torch.FloatTensor(sample_weight)  # 将 NumPy 数组转换回 PyTorch 张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afea749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_tensor(y, num_dim):\n",
    "    y_onehot = torch.zeros(y.shape[0], num_dim)\n",
    "    y_onehot.scatter_(1, y.view(-1,1), 1)\n",
    "    \n",
    "    return y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9166e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_dataframe_to_tensors(*dataframes, device=None):\n",
    "    \"\"\"\n",
    "    批量将多个 pandas DataFrame 转换为 torch Tensors 并移动到指定设备。\n",
    "\n",
    "    参数:\n",
    "        *dataframes: 任意数量的 pandas DataFrame 对象\n",
    "        device (torch.device, optional): 目标设备（例如 'cpu' 或 'cuda'），如果为 None，则自动检测设备\n",
    "    \n",
    "    返回:\n",
    "        list: 一个包含转换后 tensors 的列表\n",
    "    \"\"\"\n",
    "    \n",
    "    # 自动检测设备（优先选择 GPU，如果不可用则选择 CPU）\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    tensors = []\n",
    "    for i, df in enumerate(dataframes):\n",
    "        try:\n",
    "            if isinstance(df, pd.DataFrame):\n",
    "                # 将 DataFrame 转换为 numpy 数组\n",
    "                numpy_array = df.to_numpy()\n",
    "                # 将 numpy 数组转换为 torch Tensor 并直接在目标设备上创建\n",
    "                tensor = torch.tensor(numpy_array, dtype=torch.float32, device=device)\n",
    "                tensors.append(tensor)\n",
    "                print(f\"DataFrame {i} 已转换为 Tensor，并移动到 {tensor.device}\")\n",
    "            else:\n",
    "                raise ValueError(f\"对象 {i} 不是 pandas.DataFrame 类型，无法转换\")\n",
    "        except Exception as e:\n",
    "            print(f\"转换对象 {i} 时出错: {e}\")\n",
    "\n",
    "    return tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a911f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "    # 获取当前批次的最大长度（假设第一个元素是需要填充的部分）\n",
    "    max_length = max(len(item[0]) for item in batch)  \n",
    "\n",
    "    padded_batch = []\n",
    "    device = batch[0][0].device  # 获取第一个样本的设备\n",
    "\n",
    "    for item in batch:\n",
    "        # 填充到 max_length 长度，并确保在同一设备上\n",
    "        padded_item = torch.cat([item[0].to(device), torch.zeros(max_length - len(item[0]), device=device)])\n",
    "        padded_batch.append((padded_item, *item[1:]))  # 保留其他信息\n",
    "\n",
    "    return tuple(zip(*padded_batch))  # 转换为适合 DataLoader 的格式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0151ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMF(nn.Module):\n",
    "    '''\n",
    "    Low-rank Multimodal Fusion (去掉 omics 输入)\n",
    "    '''\n",
    "    def __init__(self, input_dims, rank, use_softmax=False):\n",
    "        '''\n",
    "        Args:\n",
    "            input_dims - a length-3 tuple, contains (audio_dim, video_dim, text_dim)\n",
    "            rank - int, specifying the size of rank in LMF\n",
    "            use_softmax - boolean, whether to apply softmax to the final output\n",
    "        '''\n",
    "        super(LMF, self).__init__()\n",
    "\n",
    "        # 现在只有三种输入数据：audio, video, text\n",
    "        self.audio_in = input_dims\n",
    "        self.video_in = input_dims\n",
    "        self.text_in = input_dims\n",
    "\n",
    "        self.output_dim = self.audio_in  # 假设输出维度与 audio 输入维度一致\n",
    "        self.rank = rank\n",
    "        self.use_softmax = use_softmax\n",
    "\n",
    "        # 为每个输入创建低秩因子\n",
    "        self.audio_factor = Parameter(torch.Tensor(self.rank, self.audio_in + 1, self.output_dim))\n",
    "        self.video_factor = Parameter(torch.Tensor(self.rank, self.video_in + 1, self.output_dim))\n",
    "        self.text_factor = Parameter(torch.Tensor(self.rank, self.text_in + 1, self.output_dim))\n",
    "\n",
    "        # 融合权重和偏置\n",
    "        self.fusion_weights = Parameter(torch.Tensor(1, self.rank))\n",
    "        self.fusion_bias = Parameter(torch.Tensor(1, self.output_dim))\n",
    "\n",
    "        # 初始化所有因子\n",
    "        xavier_normal_(self.audio_factor)\n",
    "        xavier_normal_(self.video_factor)\n",
    "        xavier_normal_(self.text_factor)\n",
    "        xavier_normal_(self.fusion_weights)\n",
    "        self.fusion_bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, audio_x, video_x, text_x):\n",
    "        '''\n",
    "        Args:\n",
    "            audio_x: tensor of shape (batch_size, audio_in)\n",
    "            video_x: tensor of shape (batch_size, video_in)\n",
    "            text_x: tensor of shape (batch_size, sequence_len, text_in)\n",
    "        '''\n",
    "        audio_h = audio_x\n",
    "        video_h = video_x\n",
    "        text_h = text_x\n",
    "        batch_size = audio_h.data.shape[0]\n",
    "\n",
    "        # 判断数据是否在 GPU 上\n",
    "        if audio_h.is_cuda:\n",
    "            DTYPE = torch.cuda.FloatTensor\n",
    "        else:\n",
    "            DTYPE = torch.FloatTensor\n",
    "\n",
    "        # 为每个输入数据添加偏置项\n",
    "        _audio_h = torch.cat((torch.ones(batch_size, 1).type(DTYPE), audio_h), dim=1)\n",
    "        _video_h = torch.cat((torch.ones(batch_size, 1).type(DTYPE), video_h), dim=1)\n",
    "        _text_h = torch.cat((torch.ones(batch_size, 1).type(DTYPE), text_h), dim=1)\n",
    "\n",
    "        # 分别对每种输入进行低秩因子分解\n",
    "        fusion_audio = torch.matmul(_audio_h, self.audio_factor)\n",
    "        fusion_video = torch.matmul(_video_h, self.video_factor)\n",
    "        fusion_text = torch.matmul(_text_h, self.text_factor)\n",
    "\n",
    "        # 低秩多模态融合：将三个输入进行逐元素相乘\n",
    "        fusion_zy = fusion_audio * fusion_video * fusion_text\n",
    "\n",
    "        # 使用融合权重进行加权\n",
    "        output = torch.matmul(self.fusion_weights, fusion_zy.permute(1, 0, 2)).squeeze() + self.fusion_bias\n",
    "        output = output.view(-1, self.output_dim)\n",
    "        \n",
    "        # 如果需要使用softmax，可以在最后应用\n",
    "        if self.use_softmax:\n",
    "            output = F.softmax(output, dim=-1)\n",
    "        \n",
    "        return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:multimoding] *",
   "language": "python",
   "name": "conda-env-multimoding-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
